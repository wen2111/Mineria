fit_coarse_acc <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl_acc, metric="Accuracy",
tuneGrid=data.frame(k = k_grid_coarse))
with(fit_coarse_acc$results,
plot(k, Accuracy, type="b", pch=16, xlab="k (coarse grid)", ylab="Accuracy (CV)"))
pred_base <- predict(fit_base, newdata=X_te)
prob_base <- predict(fit_base, newdata=X_te, type="prob")[,"Yes"]
auc_ext_base <- as.numeric(pROC::auc(pROC::roc(response=y_te, predictor=prob_base,
levels=c("No","Yes"), direction="<")))
cm_base   <- confusionMatrix(pred_base, y_te, positive="Yes")
out[[length(out)+1]] <- cbind(make_row("No", fit_base, cm_base),
data.frame(AUC_ext=auc_ext_base, Gap_AUC=fit_base$results$ROC[fit_base$results$k==fit_base$bestTune$k] - auc_ext_base))
## 11) Para cada esquema de balanceo, entrenar una vez con el k_best fijo
k_best <- fit_base$bestTune$k
one_sampling <- function(samp){
set.seed(123)
ctrl_s <- trainControl(method="cv", number=5,
classProbs=TRUE, summaryFunction=myROC,
sampling=samp)
fit <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl_s, metric="ROC",
tuneGrid=data.frame(k=k_best))
pred <- predict(fit, X_te)
prob <- predict(fit, X_te, type="prob")[,"Yes"]
auc_ext <- as.numeric(pROC::auc(pROC::roc(response=y_te, predictor=prob,
levels=c("No","Yes"), direction="<")))
cm  <- confusionMatrix(pred, y_te, positive="Yes")
cbind(make_row(paste0("Si:",samp), fit, cm),
data.frame(AUC_ext=auc_ext, Gap_AUC=fit$results$ROC[fit$results$k==fit$bestTune$k] - auc_ext))
}
for (samp in sampling_vec_fast) out[[length(out)+1]] <- one_sampling(samp)
if (run_smote) out[[length(out)+1]] <- one_sampling("smote")
if (run_rose)  out[[length(out)+1]] <- one_sampling("rose")
do.call(rbind, out)
}
ncp_map <- list(Imputado=19, reducido=8, reducido_plus=10, transformada=28)
res_knn_imputado      <- run_knn(data_imputado,      "Imputado",      res.famd_imp, ncp_map$Imputado)
res_knn_reducida      <- run_knn(data_reducida,      "reducido",      res.famd_red, ncp_map$reducido)
res_knn_reducida_plus <- run_knn(data_reducida_plus, "reducido_plus", res.famd_p,   ncp_map$reducido_plus)
res_knn_transformada  <- run_knn(data_transformada,  "transformada",  res.famd_t,   ncp_map$transformada)
knn_results <- rbind(res_knn_imputado, res_knn_reducida, res_knn_reducida_plus, res_knn_transformada)
knn_results[order(knn_results$DATA, knn_results$Balancea), ]
summ <- do.call(rbind, by(knn_results, knn_results$DATA, function(df){
df[order(-df$AUC_ext, -df$F1.score), ][1, c("DATA","Balancea","k_opt","AUC_cv","AUC_ext","Gap_AUC","F1.score","Recall..S.","Specifici","ncp_used")]
}))
summ
save.image("knn_results.RData")
summ
knn_results[order(knn_results$DATA, knn_results$Balancea), ]
run_knn <- function(
data_df, data_name, res_famd, ncp_fixed,
sampling_vec_fast = c("down","up"),  # under/over-sampling
k_grid_coarse = seq(1, 10, 1),
k_refine_span = 2,
run_smote = FALSE, run_rose = FALSE
){
## 1) Train de Kaggle, fijar levels de EXited
d <- subset(data_df, group == "train")
d$Exited <- factor(ifelse(as.character(d$Exited) == "1", "Yes", "No"),
levels = c("Yes","No"))
## 2) Obtener del objeto FAMD el conjunto de variables activas y los nombres de las filas de entrenamiento.
famd_vars      <- colnames(res_famd$call$X)
famd_train_ids <- rownames(res_famd$ind$coord)
## 3) Seleccionar las columnas según las variables activas + Exited (asegurando coherencia con las usadas en FAMD).
d_f <- d[, c(famd_vars, "Exited"), drop = FALSE]
## 4) Alinear según el orden de filas del entrenamiento FAMD (clave: el orden sigue a famd_train_ids).
all_ids    <- rownames(d_f)
common_ids <- famd_train_ids[famd_train_ids %in% all_ids]
test_ids   <- setdiff(all_ids, common_ids)
## 5) y_tr / y_te
y_tr <- d_f[common_ids, "Exited", drop = TRUE]
y_te <- d_f[test_ids,  "Exited", drop = TRUE]
## 6) Características del conjunto de prueba：Los niveles de los factores deben basarse en los del conjunto de entrenamiento original.
ncp_fixed <- min(ncp_fixed, ncol(res_famd$ind$coord))
X_tr <- as.data.frame(res_famd$ind$coord[common_ids, 1:ncp_fixed, drop = FALSE])
colnames(X_tr) <- paste0("F", seq_len(ncol(X_tr)))
## 7) Realizar una verificación de seguridad (puede mantenerse durante el desarrollo)
X_te_raw <- d_f[test_ids, famd_vars, drop = FALSE]
X_tr_raw <- d_f[common_ids, famd_vars, drop = FALSE]
for (v in famd_vars) {
if (is.factor(X_tr_raw[[v]])) {
X_te_raw[[v]] <- factor(X_te_raw[[v]], levels = levels(X_tr_raw[[v]]))
}
}
X_te <- as.data.frame(predict(res_famd, newdata = X_te_raw)$coord[, 1:ncp_fixed, drop = FALSE])
colnames(X_te) <- paste0("F", seq_len(ncol(X_te)))
## 8) verificación
stopifnot(nrow(X_tr) == length(y_tr))
stopifnot(nrow(X_te) == length(y_te))
make_row <- function(balancea, fit, cm){
data.frame(
Balancea   = balancea, Método="KNN",
Accuracy   = as.numeric(cm$overall["Accuracy"]),
Precision  = as.numeric(cm$byClass["Pos Pred Value"]),
Recall..S. = as.numeric(cm$byClass["Sensitivity"]),
Specifici  = as.numeric(cm$byClass["Specificity"]),
F1.score   = f1_from_cm(cm),
DATA       = data_name,
k_opt      = fit$bestTune$k,
AUC_cv     = max(fit$results$ROC, na.rm=TRUE),
ncp_used   = ncp_fixed
)
}
out <- list()
## 9) En el conjunto no balanceado, buscar rápidamente k0
ctrl5 <- trainControl(method="cv", number=5,
classProbs=TRUE, summaryFunction=myROC)
set.seed(123)
fit_coarse <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl5, metric="ROC",
tuneGrid=data.frame(k=k_grid_coarse))
k0 <- fit_coarse$bestTune$k
## 10) Ajustar finamente en el rango k0 ± 2
k_refine <- sort(unique(pmax(1, k0 + (-k_refine_span:k_refine_span))))
set.seed(123)
fit_base <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl5, metric="ROC",
tuneGrid=data.frame(k=k_refine))
# Accuracy
ctrl_acc <- trainControl(method="cv", number=5)
fit_coarse_acc <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl_acc, metric="Accuracy",
tuneGrid=data.frame(k = k_grid_coarse))
with(fit_coarse_acc$results,
plot(k, Accuracy, type="b", pch=16, xlab="k (coarse grid)", ylab="Accuracy (CV)"))
pred_base <- predict(fit_base, newdata=X_te)
prob_base <- predict(fit_base, newdata=X_te, type="prob")[,"Yes"]
auc_ext_base <- as.numeric(pROC::auc(pROC::roc(response=y_te, predictor=prob_base,
levels=c("No","Yes"), direction="<")))
cm_base   <- confusionMatrix(pred_base, y_te, positive="Yes")
out[[length(out)+1]] <- cbind(make_row("No", fit_base, cm_base),
data.frame(AUC_ext=auc_ext_base, Gap_AUC=fit_base$results$ROC[fit_base$results$k==fit_base$bestTune$k] - auc_ext_base))
## 11) Para cada esquema de balanceo, entrenar una vez con el k_best fijo
k_best <- fit_base$bestTune$k
one_sampling <- function(samp){
set.seed(123)
ctrl_s <- trainControl(method="cv", number=5,
classProbs=TRUE, summaryFunction=myROC,
sampling=samp)
fit <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl_s, metric="ROC",
tuneGrid=data.frame(k=k_best))
pred <- predict(fit, X_te)
prob <- predict(fit, X_te, type="prob")[,"Yes"]
auc_ext <- as.numeric(pROC::auc(pROC::roc(response=y_te, predictor=prob,
levels=c("No","Yes"), direction="<")))
cm  <- confusionMatrix(pred, y_te, positive="Yes")
cbind(make_row(paste0("Si:",samp), fit, cm),
data.frame(AUC_ext=auc_ext, Gap_AUC=fit$results$ROC[fit$results$k==fit$bestTune$k] - auc_ext))
}
for (samp in sampling_vec_fast) out[[length(out)+1]] <- one_sampling(samp)
if (run_smote) out[[length(out)+1]] <- one_sampling("smote")
if (run_rose)  out[[length(out)+1]] <- one_sampling("rose")
do.call(rbind, out)
}
ncp_map <- list(Imputado=19, reducido=8, reducido_plus=10, transformada=28)
res_knn_imputado      <- run_knn(data_imputado,      "Imputado",      res.famd_imp, ncp_map$Imputado)
res_knn_reducida      <- run_knn(data_reducida,      "reducido",      res.famd_red, ncp_map$reducido)
res_knn_reducida_plus <- run_knn(data_reducida_plus, "reducido_plus", res.famd_p,   ncp_map$reducido_plus)
res_knn_transformada  <- run_knn(data_transformada,  "transformada",  res.famd_t,   ncp_map$transformada)
knn_results <- rbind(res_knn_imputado, res_knn_reducida, res_knn_reducida_plus, res_knn_transformada)
knn_results[order(knn_results$DATA, knn_results$Balancea), ]
summ <- do.call(rbind, by(knn_results, knn_results$DATA, function(df){
df[order(-df$AUC_ext, -df$F1.score), ][1, c("DATA","Balancea","k_opt","AUC_cv","AUC_ext","Gap_AUC","F1.score","Recall..S.","Specifici","ncp_used")]
}))
summ
save.image("knn_results.RData")
twoClassSummary(data, lev = c("Yes","No"))
myROC <- function(data, lev=NULL, model=NULL){
twoClassSummary(data, lev = c("Yes","No"))
}
run_knn <- function(
data_df, data_name, res_famd, ncp_fixed,
sampling_vec_fast = c("down","up"),  # under/over-sampling
k_grid_coarse = seq(1, 9, 1),
k_refine_span = 2,
run_smote = FALSE, run_rose = FALSE
){
## 1) Train de Kaggle, fijar levels de EXited
d <- subset(data_df, group == "train")
d$Exited <- factor(ifelse(as.character(d$Exited) == "1", "Yes", "No"),
levels = c("Yes","No"))
## 2) Obtener del objeto FAMD el conjunto de variables activas y los nombres de las filas de entrenamiento.
famd_vars      <- colnames(res_famd$call$X)
famd_train_ids <- rownames(res_famd$ind$coord)
## 3) Seleccionar las columnas según las variables activas + Exited (asegurando coherencia con las usadas en FAMD).
d_f <- d[, c(famd_vars, "Exited"), drop = FALSE]
## 4) Alinear según el orden de filas del entrenamiento FAMD (clave: el orden sigue a famd_train_ids).
all_ids    <- rownames(d_f)
common_ids <- famd_train_ids[famd_train_ids %in% all_ids]
test_ids   <- setdiff(all_ids, common_ids)
## 5) y_tr / y_te
y_tr <- d_f[common_ids, "Exited", drop = TRUE]
y_te <- d_f[test_ids,  "Exited", drop = TRUE]
## 6) Características del conjunto de prueba：Los niveles de los factores deben basarse en los del conjunto de entrenamiento original.
ncp_fixed <- min(ncp_fixed, ncol(res_famd$ind$coord))
X_tr <- as.data.frame(res_famd$ind$coord[common_ids, 1:ncp_fixed, drop = FALSE])
colnames(X_tr) <- paste0("F", seq_len(ncol(X_tr)))
## 7) Realizar una verificación de seguridad (puede mantenerse durante el desarrollo)
X_te_raw <- d_f[test_ids, famd_vars, drop = FALSE]
X_tr_raw <- d_f[common_ids, famd_vars, drop = FALSE]
for (v in famd_vars) {
if (is.factor(X_tr_raw[[v]])) {
X_te_raw[[v]] <- factor(X_te_raw[[v]], levels = levels(X_tr_raw[[v]]))
}
}
X_te <- as.data.frame(predict(res_famd, newdata = X_te_raw)$coord[, 1:ncp_fixed, drop = FALSE])
colnames(X_te) <- paste0("F", seq_len(ncol(X_te)))
## 8) verificación
stopifnot(nrow(X_tr) == length(y_tr))
stopifnot(nrow(X_te) == length(y_te))
make_row <- function(balancea, fit, cm){
data.frame(
Balancea   = balancea, Método="KNN",
Accuracy   = as.numeric(cm$overall["Accuracy"]),
Precision  = as.numeric(cm$byClass["Pos Pred Value"]),
Recall..S. = as.numeric(cm$byClass["Sensitivity"]),
Specifici  = as.numeric(cm$byClass["Specificity"]),
F1.score   = f1_from_cm(cm),
DATA       = data_name,
k_opt      = fit$bestTune$k,
AUC_cv     = max(fit$results$ROC, na.rm=TRUE),
ncp_used   = ncp_fixed
)
}
out <- list()
## 9) En el conjunto no balanceado, buscar rápidamente k0
ctrl5 <- trainControl(method="cv", number=5,
classProbs=TRUE, summaryFunction=myROC)
set.seed(123)
fit_coarse <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl5, metric="ROC",
tuneGrid=data.frame(k=k_grid_coarse))
k0 <- fit_coarse$bestTune$k
## 10) Ajustar finamente en el rango k0 ± 2
k_refine <- sort(unique(pmax(1, k0 + (-k_refine_span:k_refine_span))))
set.seed(123)
fit_base <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl5, metric="ROC",
tuneGrid=data.frame(k=k_refine))
# Accuracy
ctrl_acc <- trainControl(method="cv", number=5)
fit_coarse_acc <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl_acc, metric="Accuracy",
tuneGrid=data.frame(k = k_grid_coarse))
with(fit_coarse_acc$results,
plot(k, Accuracy, type="b", pch=16, xlab="k (coarse grid)", ylab="Accuracy (CV)"))
pred_base <- predict(fit_base, newdata=X_te)
prob_base <- predict(fit_base, newdata=X_te, type="prob")[,"Yes"]
auc_ext_base <- as.numeric(pROC::auc(pROC::roc(response=y_te, predictor=prob_base,
levels=c("No","Yes"), direction="<")))
cm_base   <- confusionMatrix(pred_base, y_te, positive="Yes")
out[[length(out)+1]] <- cbind(make_row("No", fit_base, cm_base),
data.frame(AUC_ext=auc_ext_base, Gap_AUC=fit_base$results$ROC[fit_base$results$k==fit_base$bestTune$k] - auc_ext_base))
## 11) Para cada esquema de balanceo, entrenar una vez con el k_best fijo
k_best <- fit_base$bestTune$k
one_sampling <- function(samp){
set.seed(123)
ctrl_s <- trainControl(method="cv", number=5,
classProbs=TRUE, summaryFunction=myROC,
sampling=samp)
fit <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl_s, metric="ROC",
tuneGrid=data.frame(k=k_best))
pred <- predict(fit, X_te)
prob <- predict(fit, X_te, type="prob")[,"Yes"]
auc_ext <- as.numeric(pROC::auc(pROC::roc(response=y_te, predictor=prob,
levels=c("No","Yes"), direction="<")))
cm  <- confusionMatrix(pred, y_te, positive="Yes")
cbind(make_row(paste0("Si:",samp), fit, cm),
data.frame(AUC_ext=auc_ext, Gap_AUC=fit$results$ROC[fit$results$k==fit$bestTune$k] - auc_ext))
}
for (samp in sampling_vec_fast) out[[length(out)+1]] <- one_sampling(samp)
if (run_smote) out[[length(out)+1]] <- one_sampling("smote")
if (run_rose)  out[[length(out)+1]] <- one_sampling("rose")
do.call(rbind, out)
}
ncp_map <- list(Imputado=19, reducido=8, reducido_plus=10, transformada=28)
res_knn_imputado      <- run_knn(data_imputado,      "Imputado",      res.famd_imp, ncp_map$Imputado)
res_knn_reducida      <- run_knn(data_reducida,      "reducido",      res.famd_red, ncp_map$reducido)
res_knn_reducida_plus <- run_knn(data_reducida_plus, "reducido_plus", res.famd_p,   ncp_map$reducido_plus)
res_knn_transformada  <- run_knn(data_transformada,  "transformada",  res.famd_t,   ncp_map$transformada)
knn_results <- rbind(res_knn_imputado, res_knn_reducida, res_knn_reducida_plus, res_knn_transformada)
knn_results[order(knn_results$DATA, knn_results$Balancea), ]
summ <- do.call(rbind, by(knn_results, knn_results$DATA, function(df){
df[order(-df$AUC_ext, -df$F1.score), ][1, c("DATA","Balancea","k_opt","AUC_cv","AUC_ext","Gap_AUC","F1.score","Recall..S.","Specifici","ncp_used")]
}))
summ
library(caret)
library(FactoMineR)
library(ROSE)
library(pROC)
set.seed(123)
f1_from_cm <- function(cm){
p <- as.numeric(cm$byClass["Pos Pred Value"])
r <- as.numeric(cm$byClass["Sensitivity"])
2*p*r/(p+r)
}
myROC <- function(data, lev=NULL, model=NULL){
twoClassSummary(data, lev = c("Yes","No"))
}
run_knn <- function(
data_df, data_name, res_famd, ncp_fixed,
sampling_vec_fast = c("down","up"),  # under/over-sampling
k_grid_coarse = seq(1, 7, 2),
k_refine_span = 2,
run_smote = FALSE, run_rose = FALSE
){
## 1) Train de Kaggle, fijar levels de EXited
d <- subset(data_df, group == "train")
d$Exited <- factor(ifelse(as.character(d$Exited) == "1", "Yes", "No"),
levels = c("Yes","No"))
## 2) Obtener del objeto FAMD el conjunto de variables activas y los nombres de las filas de entrenamiento.
famd_vars      <- colnames(res_famd$call$X)
famd_train_ids <- rownames(res_famd$ind$coord)
## 3) Seleccionar las columnas según las variables activas + Exited (asegurando coherencia con las usadas en FAMD).
d_f <- d[, c(famd_vars, "Exited"), drop = FALSE]
## 4) Alinear según el orden de filas del entrenamiento FAMD (clave: el orden sigue a famd_train_ids).
all_ids    <- rownames(d_f)
common_ids <- famd_train_ids[famd_train_ids %in% all_ids]
test_ids   <- setdiff(all_ids, common_ids)
## 5) y_tr / y_te
y_tr <- d_f[common_ids, "Exited", drop = TRUE]
y_te <- d_f[test_ids,  "Exited", drop = TRUE]
## 6) Características del conjunto de prueba：Los niveles de los factores deben basarse en los del conjunto de entrenamiento original.
ncp_fixed <- min(ncp_fixed, ncol(res_famd$ind$coord))
X_tr <- as.data.frame(res_famd$ind$coord[common_ids, 1:ncp_fixed, drop = FALSE])
colnames(X_tr) <- paste0("F", seq_len(ncol(X_tr)))
## 7) Realizar una verificación de seguridad (puede mantenerse durante el desarrollo)
X_te_raw <- d_f[test_ids, famd_vars, drop = FALSE]
X_tr_raw <- d_f[common_ids, famd_vars, drop = FALSE]
for (v in famd_vars) {
if (is.factor(X_tr_raw[[v]])) {
X_te_raw[[v]] <- factor(X_te_raw[[v]], levels = levels(X_tr_raw[[v]]))
}
}
X_te <- as.data.frame(predict(res_famd, newdata = X_te_raw)$coord[, 1:ncp_fixed, drop = FALSE])
colnames(X_te) <- paste0("F", seq_len(ncol(X_te)))
## 8) verificación
stopifnot(nrow(X_tr) == length(y_tr))
stopifnot(nrow(X_te) == length(y_te))
make_row <- function(balancea, fit, cm){
data.frame(
Balancea   = balancea, Método="KNN",
Accuracy   = as.numeric(cm$overall["Accuracy"]),
Precision  = as.numeric(cm$byClass["Pos Pred Value"]),
Recall..S. = as.numeric(cm$byClass["Sensitivity"]),
Specifici  = as.numeric(cm$byClass["Specificity"]),
F1.score   = f1_from_cm(cm),
DATA       = data_name,
k_opt      = fit$bestTune$k,
AUC_cv     = max(fit$results$ROC, na.rm=TRUE),
ncp_used   = ncp_fixed
)
}
out <- list()
## 9) En el conjunto no balanceado, buscar rápidamente k0
ctrl5 <- trainControl(method="cv", number=5,
classProbs=TRUE, summaryFunction=myROC)
set.seed(123)
fit_coarse <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl5, metric="ROC",
tuneGrid=data.frame(k=k_grid_coarse))
k0 <- fit_coarse$bestTune$k
## 10) Ajustar finamente en el rango k0 ± 2
k_refine <- sort(unique(pmax(1, k0 + (-k_refine_span:k_refine_span))))
set.seed(123)
fit_base <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl5, metric="ROC",
tuneGrid=data.frame(k=k_refine))
# Accuracy
ctrl_acc <- trainControl(method="cv", number=5)
fit_coarse_acc <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl_acc, metric="Accuracy",
tuneGrid=data.frame(k = k_grid_coarse))
with(fit_coarse_acc$results,
plot(k, Accuracy, type="b", pch=16, xlab="k (coarse grid)", ylab="Accuracy (CV)"))
pred_base <- predict(fit_base, newdata=X_te)
prob_base <- predict(fit_base, newdata=X_te, type="prob")[,"Yes"]
auc_ext_base <- as.numeric(pROC::auc(pROC::roc(response=y_te, predictor=prob_base,
levels=c("No","Yes"), direction="<")))
cm_base   <- confusionMatrix(pred_base, y_te, positive="Yes")
out[[length(out)+1]] <- cbind(make_row("No", fit_base, cm_base),
data.frame(AUC_ext=auc_ext_base, Gap_AUC=fit_base$results$ROC[fit_base$results$k==fit_base$bestTune$k] - auc_ext_base))
## 11) Para cada esquema de balanceo, entrenar una vez con el k_best fijo
k_best <- fit_base$bestTune$k
one_sampling <- function(samp){
set.seed(123)
ctrl_s <- trainControl(method="cv", number=5,
classProbs=TRUE, summaryFunction=myROC,
sampling=samp)
fit <- train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl_s, metric="ROC",
tuneGrid=data.frame(k=k_best))
pred <- predict(fit, X_te)
prob <- predict(fit, X_te, type="prob")[,"Yes"]
auc_ext <- as.numeric(pROC::auc(pROC::roc(response=y_te, predictor=prob,
levels=c("No","Yes"), direction="<")))
cm  <- confusionMatrix(pred, y_te, positive="Yes")
cbind(make_row(paste0("Si:",samp), fit, cm),
data.frame(AUC_ext=auc_ext, Gap_AUC=fit$results$ROC[fit$results$k==fit$bestTune$k] - auc_ext))
}
for (samp in sampling_vec_fast) out[[length(out)+1]] <- one_sampling(samp)
if (run_smote) out[[length(out)+1]] <- one_sampling("smote")
if (run_rose)  out[[length(out)+1]] <- one_sampling("rose")
do.call(rbind, out)
}
ncp_map <- list(Imputado=19, reducido=8, reducido_plus=10, transformada=28)
res_knn_imputado      <- run_knn(data_imputado,      "Imputado",      res.famd_imp, ncp_map$Imputado)
res_knn_reducida      <- run_knn(data_reducida,      "reducido",      res.famd_red, ncp_map$reducido)
res_knn_reducida_plus <- run_knn(data_reducida_plus, "reducido_plus", res.famd_p,   ncp_map$reducido_plus)
res_knn_transformada  <- run_knn(data_transformada,  "transformada",  res.famd_t,   ncp_map$transformada)
# submission CSV（用内部 test, group=="test"）
write_internal_submission <- function(
data_df, data_name,
res_famd, ncp_fixed,
k_best,
sampling = NULL,
id_col   = NULL,
out_dir  = "submissions",
label_output = FALSE    # TRUE 输出 id,y_pred；默认 FALSE 输出 id,prob_yes
){
dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)
# 1) train/test internal
d_tr <- subset(data_df, group == "train")
d_te <- subset(data_df, group == "test")
d_tr$Exited <- factor(ifelse(as.character(d_tr$Exited)=="1","Yes","No"),
levels=c("Yes","No"))
# 2) famd vars + ncp
famd_vars  <- colnames(res_famd$call$X)
ncp_fixed  <- min(ncp_fixed, ncol(res_famd$ind$coord))
# 3) coord famd
if (is.null(rownames(d_tr))) rownames(d_tr) <- make.unique(sprintf("r%05d", 1:nrow(d_tr)))
famd_train_ids <- rownames(res_famd$ind$coord)
keep_ids <- famd_train_ids[famd_train_ids %in% rownames(d_tr)]
X_tr <- as.data.frame(res_famd$ind$coord[keep_ids, 1:ncp_fixed, drop=FALSE])
colnames(X_tr) <- paste0("F", seq_len(ncol(X_tr)))
y_tr <- d_tr[keep_ids, "Exited", drop=TRUE]
# 4) factor levels + proyección famd
X_te_raw <- d_te[, famd_vars, drop=FALSE]
ref_raw  <- d_tr[keep_ids, famd_vars, drop=FALSE]
for (v in famd_vars) if (is.factor(ref_raw[[v]])) {
X_te_raw[[v]] <- factor(X_te_raw[[v]], levels = levels(ref_raw[[v]]))
}
X_te <- as.data.frame(predict(res_famd, newdata = X_te_raw)$coord[, 1:ncp_fixed, drop=FALSE])
colnames(X_te) <- paste0("F", seq_len(ncol(X_te)))
# 5) k
ctrl <- caret::trainControl(method="cv", number=5,
classProbs=TRUE, summaryFunction=twoClassSummary)
if (!is.null(sampling)) ctrl$sampling <- sampling
set.seed(123)
fit <- caret::train(x=X_tr, y=y_tr, method="knn",
trControl=ctrl, metric="ROC",
tuneGrid=data.frame(k=k_best))
# 6) pred, csv
ids <- if (!is.null(id_col) && id_col %in% names(d_te)) d_te[[id_col]] else {
if (!is.null(rownames(d_te))) rownames(d_te) else seq_len(nrow(d_te))
}
bal_tag <- ifelse(is.null(sampling), "NoBal", paste0("Si-", sampling))
if (label_output) {
y_pred <- predict(fit, X_te)
submit <- data.frame(id = ids, y_pred = y_pred, stringsAsFactors = FALSE)
fn <- file.path(out_dir, sprintf("submit_%s__%s__k%d__ncp%d_labels.csv",
data_name, bal_tag, k_best, ncp_fixed))
} else {
prob <- predict(fit, X_te, type="prob")[,"Yes"]
submit <- data.frame(id = ids, prob_yes = prob, stringsAsFactors = FALSE)
fn <- file.path(out_dir, sprintf("submit_%s__%s__k%d__ncp%d.csv",
data_name, bal_tag, k_best, ncp_fixed))
}
write.csv(submit, fn, row.names = FALSE)
message("DONE", fn)
invisible(fn)
}
knn_results <- rbind(res_knn_imputado, res_knn_reducida, res_knn_reducida_plus, res_knn_transformada)
knn_results[order(knn_results$DATA, knn_results$Balancea), ]
summ <- do.call(rbind, by(knn_results, knn_results$DATA, function(df){
df[order(-df$AUC_ext, -df$F1.score), ][1, c("DATA","Balancea","k_opt","AUC_cv","AUC_ext","Gap_AUC","F1.score","Recall..S.","Specifici","ncp_used")]
}))
summ
#
get_bundle <- function(data_name){
switch(data_name,
"Imputado"      = list(df = data_imputado,      famd = res.famd_imp, ncp = ncp_map$Imputado),
"reducido"      = list(df = data_reducida,      famd = res.famd_red, ncp = ncp_map$reducido),
"reducido_plus" = list(df = data_reducida_plus, famd = res.famd_p,   ncp = ncp_map$reducido_plus),
"transformada"  = list(df = data_transformada,  famd = res.famd_t,   ncp = ncp_map$transformada),
stop("DATA desconocido: ", data_name)
)
}
# el millor model --> csv
datas <- unique(knn_results$DATA)
for (dn in datas){
best <- subset(knn_results, DATA==dn)
best <- best[order(-best$AUC_ext, -best$F1.score), ][1, ]
k_best   <- as.integer(best$k_opt)
sampling <- as.character(best$Balancea)
sampling <- if (sampling=="No") NULL else sub("^Si:", "", sampling)
b <- get_bundle(dn)
write_internal_submission(
data_df   = b$df,
data_name = dn,
res_famd  = b$famd,
ncp_fixed = b$ncp,
k_best    = k_best,
sampling  = sampling,
id_col    = NULL,
out_dir   = "submissions",
label_output = FALSE       # TRUE --> y_pred
)
}
save.image("knn_results.RData")
