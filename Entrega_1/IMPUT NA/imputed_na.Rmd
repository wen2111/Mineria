---
title: "imput na"
author: "Laura Belmonte"
date: "2025-10-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
load("~/Documents/GitHub/Mineria/.RData")
library(naniar)
library(ggplot2)
library(visdat)
library(dplyr)
library(tidyr)
library(Hmisc)
```

Los valores faltantes surgen cuando una observación carece de información registrada en una determinada variable. Su correcta gestión es fundamental, ya que eliminarlos indiscriminadamente puede reducir de manera significativa el tamaño del conjunto de datos, mientras que imputarlos de forma inadecuada puede introducir sesgos y distorsionar los resultados del análisis.  

Para abordar este problema existen diversas estrategias. Entre las más comunes se encuentran:  

- **Eliminación** de filas o columnas con un número elevado de valores faltantes.  
- **Imputación simple**, que consiste en reemplazar los valores ausentes con medidas como la media, mediana o moda.  
- **Imputación avanzada**, donde se emplean métodos más sofisticados como K-Nearest Neighbors (KNN) o modelos predictivos para estimar los valores faltantes de manera más precisa.  


# Exploración de los NA

Realizamos un test de Little para comprobar si los NA de nuestros datos son MCAR (aleatorios) o si por el contrario siguen algún patron.

El test de Little se utiliza para evaluar si los datos faltantes en un conjunto de datos siguen el mecanismo **MCAR** (*Missing Completely At Random*).

### Hipótesis

- **Hipótesis nula ($H_0$):**  
  Los valores faltantes son completamente aleatorios (MCAR).  
  Es decir, la probabilidad de que un valor esté ausente no depende de los datos observados   ni de los no observados.  

- **Hipótesis alternativa ($H_1$):**  
  Los valores faltantes no son completamente aleatorios.  
  En este caso, el patrón de datos ausentes depende de los valores observados y/o de los no   observados.  

```{r}
naniar::mcar_test(data)
```

Dado que el pvalor es ampliamente superior a 0.05, aceptamos la hipótesis nula: no hay evidencia estadística para sospechar que los valores faltantes de nuestra base de datos no son fruto de la aleatoriedad.

Vamos a visualizar la distribución de nuestros NA para las diferentes variables.

```{r}
vis_dat(data)
```

Tampoco se observa ningún patrón fuera de los generados para este problema concreto del caso del banco (ID, group, Exited).

Cantidad de NA por variable:
```{r}
gg_miss_var(data) + labs(y = "Look at all the missing ones")
```

Ya habíamos visto que en todas las variables la proporción de NA es del 30%. Esto no pasa para ID, dado que los datos test no tienen valores faltantes ni para group, variable que hemos generado nosotros para indicar si una observación es grupo train/test.

```{r}
vis_miss(data);
```

Con este gràfico estamos recalcando la información conocida por estudios diferentes i por el gràdico anterior


```{r}
pct_miss_case(data)
```

# Imputación de los NA

La imputación básica consiste en reemplazar los valores faltantes por estimaciones simples basadas en los datos disponibles, sin emplear modelos complejos. Entre los métodos más frecuentes se encuentran:

- **Reemplazo por la media o mediana:** adecuado para variables numéricas.  
- **Reemplazo por la moda:** útil para variables categóricas.  
- **Constante o valor fijo:** se puede asignar un valor específico que tenga sentido según el contexto.  

Estos métodos son fáciles de aplicar y permiten mantener el tamaño original del dataset, aunque no capturan relaciones más complejas entre las variables. Son una primera aproximación al manejo de datos faltantes, y en muchos casos se utilizan como paso previo antes de aplicar técnicas de imputación más avanzadas.

## Imputación por media y mediana

Como hemos comentado anteriormente la imputación de la media o mediana es adecuada para las variables numericas, en nuestro caso estas variables númericas hacen referencia a *age,CreditScore, Id, IsActiveMember, NumOfProducts, Tenure, X*


```{r fig.width=14, fig.height=10}
data_mean <- data %>%
  mutate(across(where(is.numeric),
                ~ Hmisc::impute(., fun = mean),
                .names = "imputed_mean_{.col}"))

data_median <- data %>%
  mutate(across(where(is.numeric),
                ~ Hmisc::impute(., fun = median),
                .names = "imputed_median_{.col}"))

data_all <- data %>%
  bind_cols(
    select(data_mean, starts_with("imputed_mean_")),
    select(data_median, starts_with("imputed_median_"))
  )


df_long_all <- data_all %>%
  select(where(is.numeric)) %>%
  pivot_longer(
    cols = everything(),
    names_to = "VariableCompleta",
    values_to = "Valor"
  ) %>%
  mutate(
    Tipo = case_when(
      grepl("^imputed_mean_", VariableCompleta) ~ "Media",
      grepl("^imputed_median_", VariableCompleta) ~ "Mediana",
      TRUE ~ "Original"
    ),
    Variable = gsub("^(imputed_mean_|imputed_median_)", "", VariableCompleta)
  )
ggplot(df_long_all, aes(x = Valor, fill = Tipo)) +
  geom_density(alpha = 0.3) +
  facet_wrap(~ Variable, scales = "free") +
  theme_minimal() +
  labs(title = "Comparación de imputación por media y mediana",
       fill = "Tipo de dato")
```

Observamos como ni la media ni la mediana parecen métodos fiables para la imputación de ninguna de las numéricas, puesto que la densidad de ninguno de las dos metodologías se ajusta bien a la densidad orignal de los datos sin NA.

## Moda 

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)

# Función para calcular la moda
get_mode <- function(x) {
  x <- x[!is.na(x)]
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Imputar categóricas con moda
data_mode <- data %>%
  mutate(across(where(is.character) | where(is.factor),
                ~ if_else(is.na(.), get_mode(.), .),
                .names = "imputed_mode_{.col}"))

# Combinar con datos originales
data_all_cat <- data %>%
  bind_cols(
    select(data_mode, starts_with("imputed_mode_"))
  )

# Preparar para visualización (tablas de frecuencias)
df_long_cat <- data_all_cat %>%
  select(where(~is.character(.) | is.factor(.))) %>%
  pivot_longer(
    cols = everything(),
    names_to = "VariableCompleta",
    values_to = "Valor"
  ) %>%
  mutate(
    Tipo = if_else(grepl("^imputed_mode_", VariableCompleta), "Moda", "Original"),
    Variable = gsub("^imputed_mode_", "", VariableCompleta)
  )

# Visualización con barras
ggplot(df_long_cat, aes(x = Valor, fill = Tipo)) +
  geom_bar(alpha = 0.6, position = "dodge") +
  facet_wrap(~ Variable, scales = "free") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Comparación de imputación por moda en variables categóricas",
       fill = "Tipo de dato",
       x = "Categoría",
       y = "Frecuencia")

# Tabla comparativa de frecuencias
tabla_comparacion <- df_long_cat %>%
  group_by(Variable, Tipo, Valor) %>%
  summarise(n = n(), .groups = "drop") %>%
  pivot_wider(names_from = Tipo, values_from = n, values_fill = 0)

print(tabla_comparacion)
```


## Media con variable target

```{r fig.width=14, fig.height=10}
data_imputado <- data

var_numericas <- names(data_imputado)[sapply(data_imputado, is.numeric)]
var_numericas <- var_numericas[var_numericas != "Exited"]

data_imputado <- data_imputado %>%
  group_by(Exited) %>%
  mutate(across(all_of(var_numericas), 
                ~ {
                  media_grupo <- mean(., na.rm = TRUE)
                  ifelse(is.na(.), media_grupo, .)
                })) %>%
  ungroup()

df_original <- data %>%
  select(where(is.numeric)) %>%
  pivot_longer(
    cols = everything(),
    names_to = "Variable",
    values_to = "Valor"
  ) %>%
  mutate(Tipo = "Original")

df_imputado <- data_imputado %>%
  select(where(is.numeric)) %>%
  pivot_longer(
    cols = everything(),
    names_to = "Variable",
    values_to = "Valor"
  ) %>%
  mutate(Tipo = "Imputado")

df_comparacion <- bind_rows(df_original, df_imputado)

ggplot(df_comparacion, aes(x = Valor, fill = Tipo)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Variable, scales = "free") +
  theme_minimal() +
  labs(title = "Comparación de distribuciones: Pre vs Post Imputación (Media por Grupo)",
       x = "Valor", 
       y = "Densidad",
       fill = "Tipo de dato") +
  scale_fill_manual(values = c("Original" = "red", "Imputado" = "blue"))
```
Vemos que la imputación de media con una variable target (en este caso exited) tampoco representa una opción fiable de cara a la imputación de datos faltantes, dado que no respeta la densidad original para ninguna de las variables numéricas

## Mi method

El método de imputación múltiple es una técnica estadística avanzada para manejar valores faltantes en un conjunto de datos.

A diferencia de las imputaciones simples, que reemplazan cada valor faltante por un único estimador como la media o la moda, MI genera varios datasets completos donde los valores faltantes son reemplazados por estimaciones diferentes basadas en modelos estadísticos que capturan la incertidumbre de los datos ausentes.

```{r, eval=FALSE}
data_mi<-data
library(dplyr)
library(mi)

# 1. Convertir caracteres a factores
data_mi <- data_mi %>%
  mutate(across(where(is.character), as.factor))

# 2. Revisar si hay columnas con todos NA o sin NA
colSums(is.na(data_mi))

# 3. Opcional: eliminar columnas sin NA
data_mi <- data_mi %>% select(where(~ any(is.na(.))))

# 4. Ejecutar MI con menos iteraciones para que sea rápido
mi_data <- mi(data_mi, seed = 335, m = 3, maxit = 5)

# Revisar resumen rápido
summary(mi_data)

# Graficar convergencia
plot(mi_data)
par(ask = FALSE)
```

Por complicaciones técnicas al implementar el método MI, en este trabajo se optó por utilizar el paquete MICE, que permite realizar imputación múltiple de manera más estable y flexible sobre datasets con valores faltantes.

## Multiple chained Equations (MICE)

Para la implementación práctica de la imputación múltiple, se utilizó el paquete MICE.
Este método permite generar múltiples datasets completos mediante modelos estadísticos iterativos, manejando tanto variables numéricas como categóricas de manera eficiente.

En primer caso eliminados aquellas variables categoricas para el analisis

```{r}
data_mice <- data

# 1. Identificar variables categóricas (character o factor)
quiCat <- which(lapply(data_mice, class) %in% c("character", "factor"))
categories <- names(data_mice)[quiCat]

# 2. Eliminar esas columnas
data_mice2 <- subset(data_mice, select = setdiff(names(data_mice), categories))
summary(data_mice2)
```

A continuación, tras mostrar los valores numéricos con summary(), visualizamos los patrones de valores faltantes (NA) en la base de datos.

```{r}
mice_plot <- VIM::aggr(data_mice2, col=c('navyblue','yellow'),
                  numbers=TRUE, sortVars=TRUE,
                  labels=names(data_mice), cex.axis=.7,
                  gap=3, ylab=c("Missing data","Pattern"))
```

Como hemos comentado anteriormente en el apartado de *exploración de NA* todas las variables tienen exactamente una representación del 30% de valores faltantes. En el panel derecho revela mediante la ayuda de un heatmap el patrón de distribución de estos valores faltantes a lo largo de las observaciones (filas), donde amarillo representa datos presentes y azul oscuro datos ausentes, mostrando que los missings no siguen un patrón completamente aleatorio como se habia supuesto con el *test de little* sino que tienden a agruparse en ciertas regiones del dataset.

A continuación realizamos la imputación de los valores faltanes de manera multivariada

```{r}
imputed_Data <- mice::mice(data_mice2, m=5, maxit = 50, method = 'pmm', seed = 500)
summary(imputed_Data)
mice::stripplot(imputed_Data, CreditScore, pch = 19, xlab = "Imputation number")
mice::stripplot(imputed_Data, NumOfProducts, pch = 19, xlab = "Imputation number")
```

En esta tabla resultado del metodo de MICE se observan con claredad que se han generado 5 datasets imputados como se ha impuesto en el codigo *m=5* usando el método Predictive Mean Matching (*method=pmm*) para las variables numéricas. La **PredictorMatrix** muestra qué variables se utilizan como predictores para imputar los valores faltantes de cada variable, mientras que variables como X e ID no se imputan pero pueden actuar como predictores.

En el moemnto de elegir la imputación más considerada nos encontramos que todas las imputaciones 1-5 parecen razonablemente consistentes entre sí, lo que indica estabilidad del método MICE. En ese caso, lo ideal sería combinar las 5 imputaciones mediante pooling de resultados en lugar de elegir una única imputación. 

```{r}
completeData <- mice::complete(imputed_Data, sample(1:5, 1))
```



