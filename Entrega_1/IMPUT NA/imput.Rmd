---
title: "imput na"
author: "Laura Belmonte"
date: "2025-10-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
load("~/Documents/GitHub/Mineria/DATA/data.RData")
library(naniar)
library(ggplot2)
library(visdat)
library(dplyr)
library(tidyr)
library(Hmisc)
```

Los valores faltantes surgen cuando una observación carece de información registrada en una determinada variable. Su correcta gestión es fundamental, ya que eliminarlos indiscriminadamente puede reducir de manera significativa el tamaño del conjunto de datos, mientras que imputarlos de forma inadecuada puede introducir sesgos y distorsionar los resultados del análisis.  

Para abordar este problema existen diversas estrategias. Entre las más comunes se encuentran:  

- **Eliminación** de filas o columnas con un número elevado de valores faltantes.  
- **Imputación simple**, que consiste en reemplazar los valores ausentes con medidas como la media, mediana o moda.  
- **Imputación avanzada**, donde se emplean métodos más sofisticados como K-Nearest Neighbors (KNN) o modelos predictivos para estimar los valores faltantes de manera más precisa.  


# Exploración de los NA

Realizamos un test de Little para comprobar si los NA de nuestros datos son MCAR (aleatorios) o si por el contrario siguen algún patron.

El test de Little se utiliza para evaluar si los datos faltantes en un conjunto de datos siguen el mecanismo **MCAR** (*Missing Completely At Random*).

### Hipótesis

- **Hipótesis nula ($H_0$):**  
  Los valores faltantes son completamente aleatorios (MCAR).  
  Es decir, la probabilidad de que un valor esté ausente no depende de los datos observados   ni de los no observados.  

- **Hipótesis alternativa ($H_1$):**  
  Los valores faltantes no son completamente aleatorios.  
  En este caso, el patrón de datos ausentes depende de los valores observados y/o de los no   observados.  

```{r}
naniar::mcar_test(data)
```

Dado que el pvalor es ampliamente superior a 0.05, aceptamos la hipótesis nula: no hay evidencia estadística para sospechar que los valores faltantes de nuestra base de datos no son fruto de la aleatoriedad.

Vamos a visualizar la distribución de nuestros NA para las diferentes variables.

```{r}
vis_dat(data)
```

Tampoco se observa ningún patrón fuera de los generados para este problema concreto del caso del banco (ID, group, Exited).

Cantidad de NA por variable:
```{r}
gg_miss_var(data) + labs(y = "Look at all the missing ones")
```

Ya habíamos visto que en todas las variables la proporción de NA es del 30%. Esto no pasa para ID, dado que los datos test no tienen valores faltantes ni para group, variable que hemos generado nosotros para indicar si una observación es grupo train/test.

```{r}
vis_miss(data);
```

Con este gràfico estamos recalcando la información conocida por estudios diferentes y por el gràdico anterior


```{r}
pct_miss_case(data)
```

# Imputación de los NA

La imputación básica consiste en reemplazar los valores faltantes por estimaciones simples basadas en los datos disponibles, sin emplear modelos complejos. Entre los métodos más frecuentes se encuentran:

- **Reemplazo por la media o mediana:** posibilidad para las variables numéricas.  
- **Reemplazo por la moda:** aplicable a variables categóricas.  
- **Constante o valor fijo:** se puede asignar un valor específico que tenga sentido según el contexto.  

Estos métodos son fáciles de aplicar y permiten mantener el tamaño original del dataset, aunque no capturan relaciones más complejas entre las variables. Son una primera aproximación al manejo de datos faltantes, y en muchos casos se utilizan como paso previo antes de aplicar técnicas de imputación más avanzadas.

## Imputación por media y mediana

Como hemos comentado anteriormente la imputación de la media o mediana es adecuada para las variables numericas. Aplicaremos estos métodos a dichas variables y comprobaremos si la distribución posterior se ajusta bien a la de los datos con NA.

```{r fig.width=14, fig.height=10}
data_mean <- data %>%
  mutate(across(where(is.numeric),
                ~ Hmisc::impute(., fun = mean),
                .names = "imputed_mean_{.col}"))

data_median <- data %>%
  mutate(across(where(is.numeric),
                ~ Hmisc::impute(., fun = median),
                .names = "imputed_median_{.col}"))

data_all <- data %>%
  bind_cols(
    select(data_mean, starts_with("imputed_mean_")),
    select(data_median, starts_with("imputed_median_"))
  )


df_long_all <- data_all %>%
  select(where(is.numeric)) %>%
  pivot_longer(
    cols = everything(),
    names_to = "VariableCompleta",
    values_to = "Valor"
  ) %>%
  mutate(
    Tipo = case_when(
      grepl("^imputed_mean_", VariableCompleta) ~ "Media",
      grepl("^imputed_median_", VariableCompleta) ~ "Mediana",
      TRUE ~ "Original"
    ),
    Variable = gsub("^(imputed_mean_|imputed_median_)", "", VariableCompleta)
  )
ggplot(df_long_all, aes(x = Valor, fill = Tipo)) +
  geom_density(alpha = 0.3) +
  facet_wrap(~ Variable, scales = "free") +
  theme_minimal() +
  labs(title = "Comparación de imputación por media y mediana",
       fill = "Tipo de dato")
```

Observamos como ni la media ni la mediana parecen métodos fiables para la imputación de ninguna de las numéricas, puesto que la densidad de ninguno de las dos metodologías se ajusta bien a la densidad orignal de los datos sin NA.

## Moda 

```{r,fig.width=14, fig.height=10}
library(dplyr)
library(tidyr)
library(ggplot2)

get_mode <- function(x) {
  ux <- na.omit(unique(x))
  ux[which.max(tabulate(match(x, ux)))]
}

data_mode <- data %>%
  mutate(across(all_of(varCat),
                ~ ifelse(is.na(.), as.character(get_mode(.)), as.character(.)),
                .names = "imputed_mode_{.col}"))

data_all <- data %>%
  select(all_of(varCat)) %>%
  mutate(across(everything(), as.character)) %>%   # <-- forzamos a character para evitar conflictos
  bind_cols(
    data_mode %>%
      select(starts_with("imputed_mode_")) %>%
      mutate(across(everything(), as.character))   # <-- igual aquí
  )

df_long_all <- data_all %>%
  pivot_longer(
    cols = everything(),
    names_to = "VariableCompleta",
    values_to = "Valor"
  ) %>%
  mutate(
    Tipo = case_when(
      grepl("^imputed_mode_", VariableCompleta) ~ "Moda",
      TRUE ~ "Original"
    ),
    Variable = gsub("^(imputed_mode_)", "", VariableCompleta)
  )

ggplot(df_long_all, aes(x = Valor, fill = Tipo)) +
  geom_bar(position = "dodge") +
  facet_wrap(~ Variable, scales = "free") +
  theme_minimal() +
  labs(title = "Comparación de imputación por moda (variables categóricas definidas)",
       fill = "Tipo de dato")

```

La imputación por moda no es el mejor metodo de imputación para las variables categoricas bien porque distorsiona severamente la distribución real de los datos, creando un sesgo excesivo hacia las categorías dominantes y eliminando la variabilidad natural del dataset original.

## Media con variable target

```{r fig.width=14, fig.height=10}
data_imputado <- data

var_numericas <- names(data_imputado)[sapply(data_imputado, is.numeric)]
var_numericas <- var_numericas[var_numericas != "Exited"]

data_imputado <- data_imputado %>%
  group_by(Exited) %>%
  mutate(across(all_of(var_numericas), 
                ~ {
                  media_grupo <- mean(., na.rm = TRUE)
                  ifelse(is.na(.), media_grupo, .)
                })) %>%
  ungroup()

df_original <- data %>%
  select(where(is.numeric)) %>%
  pivot_longer(
    cols = everything(),
    names_to = "Variable",
    values_to = "Valor"
  ) %>%
  mutate(Tipo = "Original")

df_imputado <- data_imputado %>%
  select(where(is.numeric)) %>%
  pivot_longer(
    cols = everything(),
    names_to = "Variable",
    values_to = "Valor"
  ) %>%
  mutate(Tipo = "Imputado")

df_comparacion <- bind_rows(df_original, df_imputado)

ggplot(df_comparacion, aes(x = Valor, fill = Tipo)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Variable, scales = "free") +
  theme_minimal() +
  labs(title = "Comparación de distribuciones: Pre vs Post Imputación (Media por Grupo)",
       x = "Valor", 
       y = "Densidad",
       fill = "Tipo de dato") +
  scale_fill_manual(values = c("Original" = "red", "Imputado" = "blue"))
```
Vemos que la imputación de media con una variable target (en este caso exited) tampoco representa una opción fiable de cara a la imputación de datos faltantes, dado que no respeta la densidad original para ninguna de las variables numéricas

## Mi method

El método de imputación múltiple es una técnica estadística avanzada para manejar valores faltantes en un conjunto de datos.

A diferencia de las imputaciones simples, que reemplazan cada valor faltante por un único estimador como la media o la moda, MI genera varios datasets completos donde los valores faltantes son reemplazados por estimaciones diferentes basadas en modelos estadísticos que capturan la incertidumbre de los datos ausentes.

```{r, eval=FALSE}
data_mi<-data
library(dplyr)
library(mi)

data_mi <- data_mi %>%
  mutate(across(where(is.character), as.factor))

colSums(is.na(data_mi))

data_mi <- data_mi %>% select(where(~ any(is.na(.))))

mi_data <- mi(data_mi, seed = 335, m = 3, maxit = 5)

summary(mi_data)

plot(mi_data)
par(ask = FALSE)
```

Por complicaciones técnicas al implementar el método MI, en este trabajo se optó por utilizar el paquete MICE, que permite realizar imputación múltiple de manera más estable y flexible sobre datasets con valores faltantes.

## KNN mixto
```{r, include=FALSE}
density_before_after <- function(before, after) {
  require(ggplot2)
  require(dplyr)
  require(tidyr)
  require(purrr)
  
  # Identificar variables numéricas comunes
  numeric_vars_before <- before |> 
    select(where(is.numeric)) |>
    names()
  
  numeric_vars_after <- after |> 
    select(where(is.numeric)) |>
    names()
  
  # Variables comunes entre ambos datasets
  common_vars <- intersect(numeric_vars_before, numeric_vars_after)
  
  if (length(common_vars) == 0) {
    stop("No hay variables numéricas comunes entre los datasets")
  }
  
  # Crear datos combinados
  density_df <- map_dfr(common_vars, function(var) {
    data.frame(
      variable = var,
      value = c(before[[var]], after[[var]]),
      dataset = rep(c("Original", "Imputado"), 
                   c(nrow(before), nrow(after)))
    )
  }) |>
    filter(!is.na(value))
  
  # Crear el gráfico
  ggplot(density_df, aes(x = value, color = dataset, fill = dataset)) +
    facet_wrap(~variable, scales = "free") +
    geom_density(alpha = 0.3) +
    scale_color_manual(values = c("#1f77b4", "#ff7f0e")) +
    scale_fill_manual(values = c("#1f77b4", "#ff7f0e")) +
    labs(title = "Comparación de Densidades: Original vs Imputado",
         x = "Valores", 
         y = "Densidad") +
    theme_minimal() +
    theme(legend.position = "bottom")
}
mass_before_after <- function(before, after, max_categories = 10) {
  require(ggplot2)
  require(dplyr)
  require(tidyr)
  require(purrr)
  
  # Identificar variables categóricas comunes
  categorical_vars_before <- before |> 
    select(where(~ is.factor(.) | is.character(.))) |>
    names()
  
  categorical_vars_after <- after |> 
    select(where(~ is.factor(.) | is.character(.))) |>
    names()
  
  # Variables comunes entre ambos datasets
  common_vars <- intersect(categorical_vars_before, categorical_vars_after)
  
  if (length(common_vars) == 0) {
    stop("No hay variables categóricas comunes entre los datasets")
  }
  
  # Crear datos combinados
  mass_df <- map_dfr(common_vars, function(var) {
    
    # Convertir a factor si es character
    before_vec <- if(is.character(before[[var]])) {
      as.factor(before[[var]])
    } else {
      before[[var]]
    }
    
    after_vec <- if(is.character(after[[var]])) {
      as.factor(after[[var]])
    } else {
      after[[var]]
    }
    
    # Calcular proporciones
    prop_before <- proportions(table(before_vec))
    prop_after <- proportions(table(after_vec))
    
    data.frame(
      variable = var,
      category = c(names(prop_before), names(prop_after)),
      proportion = c(prop_before, prop_after),
      dataset = rep(c("Original", "Imputado"), 
                   c(length(prop_before), length(prop_after)))
    )
  }) |>
    filter(!is.na(category))
  
  # Filtrar categorías si hay demasiadas
  if (max_categories > 0) {
    mass_df <- mass_df |>
      group_by(variable) |>
      slice_max(proportion, n = max_categories) |>
      ungroup()
  }
  
  # Crear el gráfico
  ggplot(mass_df, aes(x = category, y = proportion, 
                      color = dataset, fill = dataset)) +
    facet_wrap(~variable, scales = "free") +
    geom_col(alpha = 0.6, width = 0.7, position = "dodge") +
    scale_color_manual(values = c("#1f77b4", "#ff7f0e")) +
    scale_fill_manual(values = c("#1f77b4", "#ff7f0e")) +
    labs(title = "Comparación de Distribuciones Categóricas: Original vs Imputado",
         x = "Categorías", 
         y = "Proporción") +
    theme_minimal() +
    theme(legend.position = "bottom",
          axis.text.x = element_text(angle = 45, hjust = 1))
}
```
Tras realizar una imputación KNN con k=3 se obtuvieron resultados insatisfactorios, dando unas densidades para las numéricas que no se ajustaban a las originales previas a la imputación. Haremos el intento con k=5 siguiendo el mismo proceso.

```{r}
library(VIM)

modeCat <- function(x) {
  tab <- table(x[!is.na(x)])
  if(length(tab) == 0) return(NA)
  names(tab)[which.max(tab)]
}

variables_a_imputar <- setdiff(names(data4knn), c("ID", "Exited", "Surname"))
data4knn<-data
set.seed(8888)
imputed_data <- kNN(
  data4knn,
  variable = variables_a_imputar,
  k = 5,
  numFun = median,
  catFun = modeCat
)
data4knn_imputed_knn <- imputed_data[, !grepl("_imp", names(imputed_data))]
vis_dat(data4knn_imputed_knn)
```
Vemos que se han imputado las variables que queríamos y se han obviado ID, Surname y Exited
```{r}
density_before_after(data, data4knn_imputed_knn)
```

Vemos como la imputación por KNN mixto proporciona densidades que se alejan demasiado de la realidad en algunas variables numéricas. Por lo tanto, no podemos confiar en la imputación por knn. Miramos ahora las categóricas:
```{r}
mass_before_after(data, data4knn_imputed_knn)
```
Pese a que no se obtienen resultados muy dispares, si que observamos cierta descompensación en categorías de variables como Geography, HasCrCard o EducationLevel.

Vemos como para k=5 se obtienen las mismas conclusiones que con k=3, por tanto no podemos confiar en knn como método de imputación para nuestros datos.


## Multiple chained Equations (MICE)

Para la implementación práctica de la imputación múltiple, se utilizó el paquete MICE.
Este método permite generar múltiples datasets completos mediante modelos estadísticos iterativos, manejando tanto variables numéricas como categóricas de manera eficiente.

En primer caso eliminados aquellas variables categoricas para el analisis

```{r}
library(mice)
library(VIM)
library(caret)
library(ggplot2)
library(tidyr)

quiCat <- which(lapply(data, class) %in% c("character", "factor"))
categories <- names(data)[quiCat]
data_mice2 <- subset(data, select = setdiff(names(data), categories))
summary(data_mice2)
```

A continuación, tras mostrar los valores numéricos con summary(), visualizamos los patrones de valores faltantes (NA) en la base de datos.

```{r}
mice_plot <- VIM::aggr(data_mice2, col=c('navyblue','yellow'),
                  numbers=TRUE, sortVars=TRUE,
                  labels=names(data_mice), cex.axis=.7,
                  gap=3, ylab=c("Missing data","Pattern"))
```

Como hemos comentado anteriormente en el apartado de *exploración de NA* todas las variables tienen exactamente una representación del 30% de valores faltantes. En el panel derecho revela mediante la ayuda de un heatmap el patrón de distribución de estos valores faltantes a lo largo de las observaciones (filas), donde amarillo representa datos presentes y azul oscuro datos ausentes, mostrando que los missings no siguen un patrón completamente aleatorio como se habia supuesto con el *test de little* sino que tienden a agruparse en ciertas regiones del dataset.

A continuación realizamos la imputación de los valores faltanes de manera multivariada

```{r}
meth <- make.method(data_mice2)
for(v in names(data_mice2)){
  if(v %in% c("ID", "x")){
    meth[v] <- ""  # No imputar ID ni x
  } else {
    meth[v] <- "pmm"  # Imputar numéricas
  }
}

ini <- mice(data_mice2, maxit = 0, method = meth)
pred <- ini$predictorMatrix

imputed_Data <- mice(data_mice2, m=5, maxit=50,
                     method=meth, predictorMatrix=pred, seed=500)

summary(imputed_Data)

```

```{r}
stripplot(imputed_Data, CreditScore, pch=19, xlab="Imputation number")
stripplot(imputed_Data, NumOfProducts, pch=19, xlab="Imputation number")

# Densidad por variable específica
densityplot(imputed_Data, ~CreditScore, main="Densidad de CreditScore imputado")
densityplot(imputed_Data, ~CreditScore + NumOfProducts, main="Densidades de variables imputadas")

```

En esta tabla resultado del metodo de MICE se observan con claredad que se han generado 5 datasets imputados como se ha impuesto en el codigo *m=5* usando el método Predictive Mean Matching (*method=pmm*) para las variables numéricas. La **PredictorMatrix** muestra qué variables se utilizan como predictores para imputar los valores faltantes de cada variable, mientras que variables como X e ID no se imputan pero pueden actuar como predictores.

En el moemnto de elegir la imputación más considerada nos encontramos que todas las imputaciones 1-5 parecen razonablemente consistentes entre sí, lo que indica estabilidad del método MICE. En ese caso, lo ideal sería combinar las 5 imputaciones mediante pooling de resultados en lugar de elegir una única imputación. 

```{r}
completeData <- mice::complete(imputed_Data, sample(1:5, 1))
summary(completeData)
```



