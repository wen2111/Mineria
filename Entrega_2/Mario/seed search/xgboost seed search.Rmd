---
title: "xgboost seed search"
output: html_document
date: "2025-12-15"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(caret)
library(xgboost)
library(Matrix)
library(pROC)
library(ggplot2)
library(dplyr)
library(scales)

load("~/GitHub/Mineria/Entrega_2/Boosting/xgboot_melissa/data_reducida_con_ID.RData")
mydata <- data_reducida

```

```{r}
train <- subset(mydata, group == "train")
test  <- subset(mydata, group == "test")

test_submission_id <- test$ID
variables_eliminar <- c("group", "Surname", "ID")

train <- train[, !names(train) %in% variables_eliminar]
test  <- test[, !names(test) %in% variables_eliminar]


train$HasBalance <- ifelse(train$Balance > 0, 1, 0)
test$HasBalance  <- ifelse(test$Balance > 0, 1, 0)

train$Exited <- ifelse(train$Exited == "Yes" | train$Exited == "1", 1, 0)
```

```{r}
params <- list(
  objective = "binary:logistic",
  eval_metric = "auc",
  eta = 0.05,
  max_depth = 4,
  subsample = 0.7,
  colsample_bytree = 0.7,
  scale_pos_weight = 4
)
```

# BUCLE SEEDS

```{r}
semillas <- 101:1000

f1_train <- numeric(length(semillas))
f1_test  <- numeric(length(semillas))

### NUEVO
recall_train <- numeric(length(semillas))
recall_test  <- numeric(length(semillas))
threshold_opt <- numeric(length(semillas))

for (i in seq_along(semillas)) {
  
  set.seed(semillas[i])
  
  
  index <- createDataPartition(train$Exited, p = 0.7, list = FALSE)
  train2 <- train[index, ]
  test2  <- train[-index, ]
  
  
  predictors_train2 <- train2[, !names(train2) %in% "Exited"]
  predictors_test2  <- test2[, !names(test2) %in% "Exited"]
  
  dummy_obj <- dummyVars(~ ., data = predictors_train2, fullRank = FALSE)
  
  mat_train2 <- predict(dummy_obj, predictors_train2)
  mat_test2  <- predict(dummy_obj, predictors_test2)
  
  dtrain2 <- xgb.DMatrix(mat_train2, label = train2$Exited)
  dtest2  <- xgb.DMatrix(mat_test2,  label = test2$Exited)
  
  
  cv_res <- xgb.cv(
    params = params,
    data = dtrain2,
    nrounds = 1000,
    nfold = 5,
    stratified = TRUE,
    early_stopping_rounds = 50,
    verbose = 0,
    maximize = TRUE
  )
  
  modelo_xgb <- xgb.train(
    params = params,
    data = dtrain2,
    nrounds = cv_res$best_iteration
  )
  
  probs_train2 <- predict(modelo_xgb, dtrain2)
  probs_test2  <- predict(modelo_xgb, dtest2)

  
  roc_obj <- roc(test2$Exited, probs_test2, quiet = TRUE)
  
  coords_optimas <- coords(
    roc_obj, "best",
    ret = c("threshold", "sensitivity", "specificity"),
    best.method = "closest.topleft"
  )
  
  umbral_optimo <- coords_optimas$threshold[1]

  threshold_opt[i] <- umbral_optimo

  
  pred_class_train2 <- ifelse(probs_train2 > umbral_optimo, 1, 0)
  pred_class_test2  <- ifelse(probs_test2  > umbral_optimo, 1, 0)
  
  f_pred_train2 <- factor(pred_class_train2, levels = c(0, 1))
  f_pred_test2  <- factor(pred_class_test2,  levels = c(0, 1))
  f_real_train2 <- factor(train2$Exited, levels = c(0, 1))
  f_real_test2  <- factor(test2$Exited,  levels = c(0, 1))

  
  cm_train <- confusionMatrix(
    f_pred_train2, f_real_train2,
    positive = "1", mode = "prec_recall"
  )
  
  cm_test <- confusionMatrix(
    f_pred_test2, f_real_test2,
    positive = "1", mode = "prec_recall"
  )

  
  f1_train[i] <- cm_train$byClass["F1"]
  f1_test[i]  <- cm_test$byClass["F1"]
  
  ### NUEVO
  recall_train[i] <- cm_train$byClass["Recall"]
  recall_test[i]  <- cm_test$byClass["Recall"]
  
  cat("Semilla:", semillas[i],
      "| F1 Train:", round(f1_train[i], 4),
      "| F1 Test:", round(f1_test[i], 4),
      "| Recall Test:", round(recall_test[i], 4),
      "| Threshold:", round(umbral_optimo, 4), "\n")
}

```

# Los mejores resultados

```{r}

df <- data.frame(
  semilla = semillas,
  F1_train = f1_train,
  F1_test  = f1_test,
  Recall_train = recall_train,
  Recall_test  = recall_test,
  Threshold_optimo = threshold_opt
)

ranking_final <- df[order(-df$F1_test), ][1:30, ]
ranking_final
```

