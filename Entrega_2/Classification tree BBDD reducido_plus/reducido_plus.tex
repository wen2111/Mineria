% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{tocloft}
\renewcommand{\contentsname}{\hfill\LARGE\textbf{ÍNDICE}\hfill}
\renewcommand{\cftaftertoctitle}{\hfill}
\addtocontents{toc}{\protect\thispagestyle{empty}}
\addtocontents{toc}{\protect\setcounter{tocdepth}{3}}
\renewcommand{\cftsecafterpnum}{\vspace{8pt}}
\renewcommand{\cftsubsecafterpnum}{\vspace{5pt}}
\renewcommand{\cftsubsubsecafterpnum}{\vspace{3pt}}
\renewcommand{\cftdotsep}{1.5}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Classification Tree bbdd reducido\_plus},
  pdfauthor={Grupo 5},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Classification Tree bbdd reducido\_plus}
\author{Grupo 5}
\date{}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\section{Base de datos reducido\_plus SIN
BALANCEAR}\label{base-de-datos-reducido_plus-sin-balancear}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data4tree}\OtherTok{\textless{}{-}}\NormalTok{data\_reducida\_plus[}\DecValTok{0}\SpecialCharTok{:}\DecValTok{7000}\NormalTok{,]}
\NormalTok{datatest}\OtherTok{\textless{}{-}}\NormalTok{data\_reducida\_plus[}\DecValTok{7001}\SpecialCharTok{:}\DecValTok{10000}\NormalTok{,]}
\NormalTok{ind }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(data4tree), }\FloatTok{0.7}\SpecialCharTok{*}\FunctionTok{nrow}\NormalTok{(data4tree))}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ data4tree[ind,]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ data4tree[}\SpecialCharTok{{-}}\NormalTok{ind,]}
\end{Highlighting}
\end{Shaded}

\subsection{Método cp=0}\label{muxe9todo-cp0}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree }\OtherTok{\textless{}{-}} \FunctionTok{rpart}\NormalTok{(Exited }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{cp =} \DecValTok{0}\NormalTok{)}
\FunctionTok{printcp}\NormalTok{(tree)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Classification tree:
## rpart(formula = Exited ~ ., data = train, cp = 0)
## 
## Variables actually used in tree construction:
## [1] Age                 Balance             CreditScore        
## [4] EstimatedSalary     Gender              Geography          
## [7] IsActiveMember      NumOfProducts_grupo
## 
## Root node error: 1018/4900 = 0.20776
## 
## n= 4900 
## 
##            CP nsplit rel error  xerror     xstd
## 1  1.6045e-02      0   1.00000 1.00000 0.027897
## 2  1.1788e-02      4   0.91847 0.94401 0.027303
## 3  6.2213e-03      6   0.89489 0.92927 0.027141
## 4  5.8939e-03      9   0.87623 0.93320 0.027184
## 5  5.2390e-03     10   0.87033 0.93222 0.027173
## 6  4.9116e-03     13   0.85462 0.92338 0.027075
## 7  3.6018e-03     15   0.84479 0.91257 0.026953
## 8  2.9470e-03     22   0.80943 0.92141 0.027053
## 9  2.4558e-03     42   0.74558 0.93026 0.027151
## 10 1.9646e-03     45   0.73772 0.93811 0.027238
## 11 1.6372e-03     53   0.72200 0.95285 0.027399
## 12 1.4735e-03     56   0.71709 0.96071 0.027484
## 13 1.4033e-03     60   0.71120 0.96758 0.027557
## 14 1.2279e-03     67   0.70138 0.96758 0.027557
## 15 1.1788e-03     75   0.68369 0.96660 0.027547
## 16 9.8232e-04     80   0.67780 0.97741 0.027662
## 17 6.5488e-04    103   0.65521 0.99902 0.027887
## 18 4.9116e-04    106   0.65324 1.00491 0.027947
## 19 2.8066e-04    108   0.65226 1.01572 0.028057
## 20 9.8232e-05    115   0.65029 1.03045 0.028205
## 21 0.0000e+00    125   0.64931 1.03635 0.028264
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotcp}\NormalTok{(tree)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{reducido_plus_files/figure-latex/unnamed-chunk-3-1.pdf}}

\subsubsection{Elección cp óptimo}\label{elecciuxf3n-cp-uxf3ptimo}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xerror }\OtherTok{\textless{}{-}}\NormalTok{ tree}\SpecialCharTok{$}\NormalTok{cptable[,}\StringTok{"xerror"}\NormalTok{]}
\NormalTok{xerror}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         1         2         3         4         5         6         7         8 
## 1.0000000 0.9440079 0.9292731 0.9332024 0.9322200 0.9233792 0.9125737 0.9214145 
##         9        10        11        12        13        14        15        16 
## 0.9302554 0.9381139 0.9528487 0.9607073 0.9675835 0.9675835 0.9666012 0.9774067 
##        17        18        19        20        21 
## 0.9990177 1.0049116 1.0157171 1.0304519 1.0363458
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{imin.xerror }\OtherTok{\textless{}{-}} \FunctionTok{which.min}\NormalTok{(xerror)}
\NormalTok{imin.xerror}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 7 
## 7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree}\SpecialCharTok{$}\NormalTok{cptable[imin.xerror, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           CP       nsplit    rel error       xerror         xstd 
##  0.003601834 15.000000000  0.844793713  0.912573674  0.026953302
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{upper.xerror }\OtherTok{\textless{}{-}}\NormalTok{ xerror[imin.xerror] }\SpecialCharTok{+}\NormalTok{ tree}\SpecialCharTok{$}\NormalTok{cptable[imin.xerror, }\StringTok{"xstd"}\NormalTok{]}
\NormalTok{upper.xerror}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        7 
## 0.939527
\end{verbatim}

\paragraph{Cp mínimo}\label{cp-muxednimo}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree2 }\OtherTok{\textless{}{-}} \FunctionTok{prune}\NormalTok{(tree, }\AttributeTok{cp =} \FloatTok{0.002967359}\NormalTok{)}
\NormalTok{importance }\OtherTok{\textless{}{-}}\NormalTok{ tree2}\SpecialCharTok{$}\NormalTok{variable.importance}
\NormalTok{importance }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\DecValTok{100}\SpecialCharTok{*}\NormalTok{importance}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{(importance), }\DecValTok{1}\NormalTok{)}
\NormalTok{importance}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 Age NumOfProducts_grupo             Balance         CreditScore 
##                36.8                33.6                 8.6                 6.9 
##      IsActiveMember           Geography     EstimatedSalary              Gender 
##                 6.5                 4.5                 2.8                 0.2
\end{verbatim}

Matriz de confusión para train

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 3193  460
##          1  689  558
##                                           
##                Accuracy : 0.7655          
##                  95% CI : (0.7534, 0.7773)
##     No Information Rate : 0.7922          
##     P-Value [Acc > NIR] : 1               
##                                           
##                   Kappa : 0.3422          
##                                           
##  Mcnemar's Test P-Value : 1.741e-11       
##                                           
##             Sensitivity : 0.5481          
##             Specificity : 0.8225          
##          Pos Pred Value : 0.4475          
##          Neg Pred Value : 0.8741          
##              Prevalence : 0.2078          
##          Detection Rate : 0.1139          
##    Detection Prevalence : 0.2545          
##       Balanced Accuracy : 0.6853          
##                                           
##        'Positive' Class : 1               
## 
\end{verbatim}

Matriz de confusión para test

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 1360  225
##          1  308  207
##                                          
##                Accuracy : 0.7462         
##                  95% CI : (0.727, 0.7647)
##     No Information Rate : 0.7943         
##     P-Value [Acc > NIR] : 1.0000000      
##                                          
##                   Kappa : 0.2749         
##                                          
##  Mcnemar's Test P-Value : 0.0003826      
##                                          
##             Sensitivity : 0.47917        
##             Specificity : 0.81535        
##          Pos Pred Value : 0.40194        
##          Neg Pred Value : 0.85804        
##              Prevalence : 0.20571        
##          Detection Rate : 0.09857        
##    Detection Prevalence : 0.24524        
##       Balanced Accuracy : 0.64726        
##                                          
##        'Positive' Class : 1              
## 
\end{verbatim}

F1 score

\begin{verbatim}
## f1 datos train 0.4927152 f1 datos test 0.43717
\end{verbatim}

Los resultados no son satisfactorios: hay mucho overfitting

\paragraph{Cp mínimo+ error
estándar}\label{cp-muxednimo-error-estuxe1ndar}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{icp }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(tree}\SpecialCharTok{$}\NormalTok{cptable[, }\StringTok{"xerror"}\NormalTok{] }\SpecialCharTok{\textless{}=}\NormalTok{ upper.xerror)[}\DecValTok{1}\NormalTok{]}
\NormalTok{cp\_optimo\_1se }\OtherTok{\textless{}{-}}\NormalTok{ tree}\SpecialCharTok{$}\NormalTok{cptable[icp, }\StringTok{"CP"}\NormalTok{]}
\NormalTok{tree3 }\OtherTok{\textless{}{-}} \FunctionTok{prune}\NormalTok{(tree, }\AttributeTok{cp =}\NormalTok{ cp\_optimo\_1se)}
\NormalTok{importance }\OtherTok{\textless{}{-}}\NormalTok{ tree3}\SpecialCharTok{$}\NormalTok{variable.importance}
\NormalTok{importance }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\DecValTok{100}\SpecialCharTok{*}\NormalTok{importance}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{(importance), }\DecValTok{1}\NormalTok{)}
\NormalTok{importance}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 Age NumOfProducts_grupo      IsActiveMember             Balance 
##                52.0                33.5                 6.4                 5.9 
##           Geography         CreditScore     EstimatedSalary              Gender 
##                 1.1                 0.5                 0.4                 0.2
\end{verbatim}

Vemos como han cambiado los valores de importancia. Ahora se comprovará
si mejoran los KPI. Matriz de confusión para train

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 3428  600
##          1  454  418
##                                           
##                Accuracy : 0.7849          
##                  95% CI : (0.7731, 0.7963)
##     No Information Rate : 0.7922          
##     P-Value [Acc > NIR] : 0.9003          
##                                           
##                   Kappa : 0.3101          
##                                           
##  Mcnemar's Test P-Value : 7.958e-06       
##                                           
##             Sensitivity : 0.41061         
##             Specificity : 0.88305         
##          Pos Pred Value : 0.47936         
##          Neg Pred Value : 0.85104         
##              Prevalence : 0.20776         
##          Detection Rate : 0.08531         
##    Detection Prevalence : 0.17796         
##       Balanced Accuracy : 0.64683         
##                                           
##        'Positive' Class : 1               
## 
\end{verbatim}

Matriz de confusión para test

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 1472  280
##          1  196  152
##                                           
##                Accuracy : 0.7733          
##                  95% CI : (0.7548, 0.7911)
##     No Information Rate : 0.7943          
##     P-Value [Acc > NIR] : 0.9913045       
##                                           
##                   Kappa : 0.2525          
##                                           
##  Mcnemar's Test P-Value : 0.0001422       
##                                           
##             Sensitivity : 0.35185         
##             Specificity : 0.88249         
##          Pos Pred Value : 0.43678         
##          Neg Pred Value : 0.84018         
##              Prevalence : 0.20571         
##          Detection Rate : 0.07238         
##    Detection Prevalence : 0.16571         
##       Balanced Accuracy : 0.61717         
##                                           
##        'Positive' Class : 1               
## 
\end{verbatim}

F1 score

\begin{verbatim}
## f1 datos train 0.442328 f1 datos test 0.3897436
\end{verbatim}

Sigue habiendo mucho overfitting

\subsection{Método Caret}\label{muxe9todo-caret}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret.rpart }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(Exited }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{method =} \StringTok{"rpart"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ train,}
 \AttributeTok{tuneLength =} \DecValTok{20}\NormalTok{,}
 \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{10}\NormalTok{))}
\FunctionTok{ggplot}\NormalTok{(caret.rpart)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{reducido_plus_files/figure-latex/unnamed-chunk-13-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rpart.plot}\NormalTok{(caret.rpart}\SpecialCharTok{$}\NormalTok{finalModel)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{reducido_plus_files/figure-latex/unnamed-chunk-13-2.pdf}}
Importancia de las variables:
\pandocbounded{\includegraphics[keepaspectratio]{reducido_plus_files/figure-latex/unnamed-chunk-14-1.pdf}}
Las predicciones:

Matriz de confusión datos train

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 3179  416
##          1  703  602
##                                           
##                Accuracy : 0.7716          
##                  95% CI : (0.7596, 0.7833)
##     No Information Rate : 0.7922          
##     P-Value [Acc > NIR] : 0.9998          
##                                           
##                   Kappa : 0.3716          
##                                           
##  Mcnemar's Test P-Value : <2e-16          
##                                           
##             Sensitivity : 0.5914          
##             Specificity : 0.8189          
##          Pos Pred Value : 0.4613          
##          Neg Pred Value : 0.8843          
##              Prevalence : 0.2078          
##          Detection Rate : 0.1229          
##    Detection Prevalence : 0.2663          
##       Balanced Accuracy : 0.7051          
##                                           
##        'Positive' Class : 1               
## 
\end{verbatim}

Matriz de confusión datos test:

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 1472  280
##          1  196  152
##                                           
##                Accuracy : 0.7733          
##                  95% CI : (0.7548, 0.7911)
##     No Information Rate : 0.7943          
##     P-Value [Acc > NIR] : 0.9913045       
##                                           
##                   Kappa : 0.2525          
##                                           
##  Mcnemar's Test P-Value : 0.0001422       
##                                           
##             Sensitivity : 0.35185         
##             Specificity : 0.88249         
##          Pos Pred Value : 0.43678         
##          Neg Pred Value : 0.84018         
##              Prevalence : 0.20571         
##          Detection Rate : 0.07238         
##    Detection Prevalence : 0.16571         
##       Balanced Accuracy : 0.61717         
##                                           
##        'Positive' Class : 1               
## 
\end{verbatim}

Los F1score:

\begin{verbatim}
## f1 datos train 0.5182953 f1 datos test 0.3897436
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Valores muy pobres de F1 y recall
\item
  Indicios de overfitting
\end{itemize}

\subsection{Conclusiones para data\_reducido\_plus sin
balancear}\label{conclusiones-para-data_reducido_plus-sin-balancear}

Resultados bastante mejorables tanto con el paquete Caret como
encontrando el Cp óptimo a partir del árbol más grande (Cp=0). Sumar la
desviación típica tampoco mejora los resultados. Probaremos balanceando
los datos.

\section{Base de datos reducido\_plus
BALANCEO}\label{base-de-datos-reducido_plus-balanceo}

A continuación se buscará para diferentes niveles de balanceo dónde se
obtienen mejores kpi con caret

\begin{verbatim}
## 
## S'està adjuntant el paquet: 'dplyr'
\end{verbatim}

\begin{verbatim}
## Els següents objectes estan emmascarats des de 'package:stats':
## 
##     filter, lag
\end{verbatim}

\begin{verbatim}
## Els següents objectes estan emmascarats des de 'package:base':
## 
##     intersect, setdiff, setequal, union
\end{verbatim}

\begin{verbatim}
##         F1_Train   F1_Test Sensitivity_Train Sensitivity_Test Specificity_Train
## p_0.05       NaN       NaN        0.00000000       0.00000000         1.0000000
## p_0.1  0.1036078 0.0623608        0.05500982       0.03240741         0.9981968
## p_0.15 0.2692003 0.2209738        0.16699411       0.13657407         0.9806801
## p_0.2  0.3264402 0.2650177        0.21709234       0.17361111         0.9703761
## p_0.25 0.4149004 0.3788820        0.31728880       0.28240741         0.9443586
## p_0.3  0.4487334 0.3976608        0.36542240       0.31481481         0.9309634
## p_0.35 0.5036045 0.4300000        0.48035363       0.39814815         0.8879444
## p_0.4  0.5122713 0.4432314        0.56385069       0.46990741         0.8328181
## p_0.45 0.5109489 0.4532110        0.65324165       0.57175926         0.7630088
## p_0.5  0.4924242 0.4219887        0.70235756       0.60416667         0.6983514
##        Specificity_Test Accuracy_Train Accuracy_Test
## p_0.05        1.0000000      0.7922449     0.7942857
## p_0.1         0.9982014      0.8022449     0.7995238
## p_0.15        0.9742206      0.8116327     0.8019048
## p_0.2         0.9646283      0.8138776     0.8019048
## p_0.25        0.9460432      0.8140816     0.8095238
## p_0.3         0.9304556      0.8134694     0.8038095
## p_0.35        0.8824940      0.8032653     0.7828571
## p_0.4         0.8315348      0.7769388     0.7571429
## p_0.45        0.7535971      0.7402041     0.7161905
## p_0.5         0.6738609      0.6991837     0.6595238
\end{verbatim}

\subsection{Conclusiones balanceo}\label{conclusiones-balanceo}

\begin{itemize}
\tightlist
\item
  Se obtienen mejores resultados que sin balancear
\item
  con balanceo 50-50 se obtiene el mejor recall. Se logra detectar 6-7
  de cada 10 clientes que abandonan el banco.
\item
  En términos de F-score, los mejores resultados se obtienen también con
  balanceo 50-50.
\end{itemize}

\end{document}
