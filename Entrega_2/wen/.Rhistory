probs_train2 <- predict(modelo_xgb, dtrain2)
# Convertimos probabilidad a clase usando el umbral optimizado
pred_class_train2 <- ifelse(probs_train2 > umbral_optimo, 1, 0)
pred_class_test2  <- ifelse(probs_test2 > umbral_optimo, 1, 0)
# Convertimos a Factor para caret (asegurando niveles 0 y 1)
f_pred_train2 <- factor(pred_class_train2, levels = c(0, 1))
f_pred_test2  <- factor(pred_class_test2, levels = c(0, 1))
f_real_train2 <- factor(train2$Exited, levels = c(0, 1))
f_real_test2  <- factor(test2$Exited, levels = c(0, 1))
# Matrices de Confusión
cm_train <- confusionMatrix(f_pred_train2, f_real_train2, positive = "1", mode = "prec_recall")
cm_test  <- confusionMatrix(f_pred_test2, f_real_test2, positive = "1", mode = "prec_recall")
# Tabla Resumen
resultados <- data.frame(
Dataset = c("Train2", "Test2"),
Accuracy = c(cm_train$overall["Accuracy"], cm_test$overall["Accuracy"]),
Precision = c(cm_train$byClass["Precision"], cm_test$byClass["Precision"]),
Recall = c(cm_train$byClass["Sensitivity"], cm_test$byClass["Sensitivity"]),
F1_Score = c(cm_train$byClass["F1"], cm_test$byClass["F1"])
)
print(resultados)
#####################################################
### 7. CÁLCULO DE KPIS (TRAIN2 VS TEST2)
#####################################################
umbral_optimo<-0.48
# Obtenemos predicciones también para train2 para ver si hay overfitting
probs_train2 <- predict(modelo_xgb, dtrain2)
# Convertimos probabilidad a clase usando el umbral optimizado
pred_class_train2 <- ifelse(probs_train2 > umbral_optimo, 1, 0)
pred_class_test2  <- ifelse(probs_test2 > umbral_optimo, 1, 0)
# Convertimos a Factor para caret (asegurando niveles 0 y 1)
f_pred_train2 <- factor(pred_class_train2, levels = c(0, 1))
f_pred_test2  <- factor(pred_class_test2, levels = c(0, 1))
f_real_train2 <- factor(train2$Exited, levels = c(0, 1))
f_real_test2  <- factor(test2$Exited, levels = c(0, 1))
# Matrices de Confusión
cm_train <- confusionMatrix(f_pred_train2, f_real_train2, positive = "1", mode = "prec_recall")
cm_test  <- confusionMatrix(f_pred_test2, f_real_test2, positive = "1", mode = "prec_recall")
# Tabla Resumen
resultados <- data.frame(
Dataset = c("Train2", "Test2"),
Accuracy = c(cm_train$overall["Accuracy"], cm_test$overall["Accuracy"]),
Precision = c(cm_train$byClass["Precision"], cm_test$byClass["Precision"]),
Recall = c(cm_train$byClass["Sensitivity"], cm_test$byClass["Sensitivity"]),
F1_Score = c(cm_train$byClass["F1"], cm_test$byClass["F1"])
)
print(resultados)
#####################################################
### 7. CÁLCULO DE KPIS (TRAIN2 VS TEST2)
#####################################################
umbral_optimo<-0.47
# Obtenemos predicciones también para train2 para ver si hay overfitting
probs_train2 <- predict(modelo_xgb, dtrain2)
# Convertimos probabilidad a clase usando el umbral optimizado
pred_class_train2 <- ifelse(probs_train2 > umbral_optimo, 1, 0)
pred_class_test2  <- ifelse(probs_test2 > umbral_optimo, 1, 0)
# Convertimos a Factor para caret (asegurando niveles 0 y 1)
f_pred_train2 <- factor(pred_class_train2, levels = c(0, 1))
f_pred_test2  <- factor(pred_class_test2, levels = c(0, 1))
f_real_train2 <- factor(train2$Exited, levels = c(0, 1))
f_real_test2  <- factor(test2$Exited, levels = c(0, 1))
# Matrices de Confusión
cm_train <- confusionMatrix(f_pred_train2, f_real_train2, positive = "1", mode = "prec_recall")
cm_test  <- confusionMatrix(f_pred_test2, f_real_test2, positive = "1", mode = "prec_recall")
# Tabla Resumen
resultados <- data.frame(
Dataset = c("Train2", "Test2"),
Accuracy = c(cm_train$overall["Accuracy"], cm_test$overall["Accuracy"]),
Precision = c(cm_train$byClass["Precision"], cm_test$byClass["Precision"]),
Recall = c(cm_train$byClass["Sensitivity"], cm_test$byClass["Sensitivity"]),
F1_Score = c(cm_train$byClass["F1"], cm_test$byClass["F1"])
)
print(resultados)
#####################################################
### 7. CÁLCULO DE KPIS (TRAIN2 VS TEST2)
#####################################################
umbral_optimo<-0.48
# Obtenemos predicciones también para train2 para ver si hay overfitting
probs_train2 <- predict(modelo_xgb, dtrain2)
# Convertimos probabilidad a clase usando el umbral optimizado
pred_class_train2 <- ifelse(probs_train2 > umbral_optimo, 1, 0)
pred_class_test2  <- ifelse(probs_test2 > umbral_optimo, 1, 0)
# Convertimos a Factor para caret (asegurando niveles 0 y 1)
f_pred_train2 <- factor(pred_class_train2, levels = c(0, 1))
f_pred_test2  <- factor(pred_class_test2, levels = c(0, 1))
f_real_train2 <- factor(train2$Exited, levels = c(0, 1))
f_real_test2  <- factor(test2$Exited, levels = c(0, 1))
# Matrices de Confusión
cm_train <- confusionMatrix(f_pred_train2, f_real_train2, positive = "1", mode = "prec_recall")
cm_test  <- confusionMatrix(f_pred_test2, f_real_test2, positive = "1", mode = "prec_recall")
# Tabla Resumen
resultados <- data.frame(
Dataset = c("Train2", "Test2"),
Accuracy = c(cm_train$overall["Accuracy"], cm_test$overall["Accuracy"]),
Precision = c(cm_train$byClass["Precision"], cm_test$byClass["Precision"]),
Recall = c(cm_train$byClass["Sensitivity"], cm_test$byClass["Sensitivity"]),
F1_Score = c(cm_train$byClass["F1"], cm_test$byClass["F1"])
)
print(resultados)
# 1. Calculamos las probabilidades con el modelo XGBoost
probs_kaggle <- predict(modelo_xgb, dkaggle)
#####################################################
### 7. CÁLCULO DE KPIS (TRAIN2 VS TEST2)
#####################################################
umbral_optimo<-0.47
# Obtenemos predicciones también para train2 para ver si hay overfitting
probs_train2 <- predict(modelo_xgb, dtrain2)
# Convertimos probabilidad a clase usando el umbral optimizado
pred_class_train2 <- ifelse(probs_train2 > umbral_optimo, 1, 0)
pred_class_test2  <- ifelse(probs_test2 > umbral_optimo, 1, 0)
# Convertimos a Factor para caret (asegurando niveles 0 y 1)
f_pred_train2 <- factor(pred_class_train2, levels = c(0, 1))
f_pred_test2  <- factor(pred_class_test2, levels = c(0, 1))
f_real_train2 <- factor(train2$Exited, levels = c(0, 1))
f_real_test2  <- factor(test2$Exited, levels = c(0, 1))
# Matrices de Confusión
cm_train <- confusionMatrix(f_pred_train2, f_real_train2, positive = "1", mode = "prec_recall")
cm_test  <- confusionMatrix(f_pred_test2, f_real_test2, positive = "1", mode = "prec_recall")
# Tabla Resumen
resultados <- data.frame(
Dataset = c("Train2", "Test2"),
Accuracy = c(cm_train$overall["Accuracy"], cm_test$overall["Accuracy"]),
Precision = c(cm_train$byClass["Precision"], cm_test$byClass["Precision"]),
Recall = c(cm_train$byClass["Sensitivity"], cm_test$byClass["Sensitivity"]),
F1_Score = c(cm_train$byClass["F1"], cm_test$byClass["F1"])
)
print(resultados)
mydata <- data_reducida
#####################################################
# PREPARACIÓN
#####################################################
# Separar Train y Test (para Kaggle, Exited vacía)
train <- subset(mydata, group == "train")
test  <- subset(mydata, group == "test")
# Guardar ID para submission y eliminar variables innecesarias para el modelo
test_submission_id <- test$ID
variables_eliminar <- c("group", "Surname", "ID")
train <- train[, !names(train) %in% variables_eliminar]
test  <- test[, !names(test) %in% c("group", "Surname", "ID")]
#####################################################
### FEATURE ENGINEERING
#####################################################
# Creamos HasBalance porque los que tienen saldo se van mas
# XGBoost prefiere números: 1 si tiene saldo, 0 si no.
train$HasBalance <- ifelse(train$Balance > 0, 1, 0)
test$HasBalance  <- ifelse(test$Balance > 0, 1, 0)
train$Balance<-NULL
test$Balance<-NULL
# Convertir la variable objetivo a numérica 0/1 para XGBoost
# "Yes" o "1" es la clase positiva.
train$Exited <- ifelse(train$Exited == "Yes" | train$Exited == "1", 1, 0)
#####################################################
### 3. PARTICIÓN INTERNA (TRAIN2 / TEST2)
#####################################################
set.seed(689)
index <- createDataPartition(train$Exited, p = 0.7, list = FALSE)
train2 <- train[index, ]
test2  <- train[-index, ]
# Separamos predictores de la variable objetivo
predictors_train2 <- train2[, !names(train2) %in% "Exited"]
predictors_test2  <- test2[, !names(test2) %in% "Exited"]
predictors_kaggle <- test[, !names(test) %in% "Exited"] # El test de Kaggle no tiene Exited
# Creamos el esquema de transformación
dummy_obj <- dummyVars(~ ., data = predictors_train2, fullRank = FALSE)
# Aplicamos el esquema a los 3 conjuntos de datos
mat_train2  <- predict(dummy_obj, newdata = predictors_train2)
mat_test2   <- predict(dummy_obj, newdata = predictors_test2)
mat_kaggle  <- predict(dummy_obj, newdata = predictors_kaggle)
# Convertimos a formato nativo de XGBoost (DMatrix)
# test2 y train2 llevan etiqueta (label), kaggle no.
dtrain2 <- xgb.DMatrix(data = mat_train2, label = train2$Exited)
dtest2  <- xgb.DMatrix(data = mat_test2, label = test2$Exited)
dkaggle <- xgb.DMatrix(data = mat_kaggle)
#####################################################
### 5. ENTRENAMIENTO XGBOOST CON CV
#####################################################
# Configuración para subir el F1 (Atención a scale_pos_weight)
params <- list(
objective = "binary:logistic",
eval_metric = "auc",
eta = 0.05,              # Aprendizaje lento para evitar overfitting
max_depth = 4,           # Árboles no muy profundos
subsample = 0.7,
colsample_bytree = 0.7,
scale_pos_weight = 4     # CLAVE: Compensar desbalanceo (aprox 80/20 ratio)
)
set.seed(689)
# Cross Validation para encontrar el número óptimo de rondas
cv_res <- xgb.cv(
params = params,
data = dtrain2,
nrounds = 1000,
nfold = 5,
stratified = TRUE,       # CLAVE: Evita el error de "dataset empty"
early_stopping_rounds = 50,
print_every_n = 50,
maximize = TRUE
)
# Entrenar modelo final con la mejor iteración encontrada
modelo_xgb <- xgb.train(
params = params,
data = dtrain2,
nrounds = cv_res$best_iteration
)
#####################################################
### 6. EVALUACIÓN Y UMBRAL ÓPTIMO (TEST2)
#####################################################
# Predecimos probabilidades sobre la validación interna
probs_test2 <- predict(modelo_xgb, dtest2)
# Curva ROC para buscar el mejor punto de corte
roc_obj <- roc(test2$Exited, probs_test2)
# Buscamos el umbral que maximiza la suma de Sensibilidad y Especificidad
coords_optimas <- coords(roc_obj, "best",
ret = c("threshold", "sensitivity", "specificity"),
best.method = "closest.topleft")
umbral_optimo <- coords_optimas$threshold
cat("El umbral optimizado es:", umbral_optimo, "\n")
################## GRAFICO ROC ########################
plot(roc_obj, print.auc = TRUE, print.thres = "best", col="blue", main="ROC Curve (Validation)")
#####################################################
### 7. CÁLCULO DE KPIS (TRAIN2 VS TEST2)
#####################################################
umbral_optimo<-0.47
# Obtenemos predicciones también para train2 para ver si hay overfitting
probs_train2 <- predict(modelo_xgb, dtrain2)
umbral_optimo <- coords_optimas$threshold
# Obtenemos predicciones también para train2 para ver si hay overfitting
probs_train2 <- predict(modelo_xgb, dtrain2)
# Convertimos probabilidad a clase usando el umbral optimizado
pred_class_train2 <- ifelse(probs_train2 > umbral_optimo, 1, 0)
pred_class_test2  <- ifelse(probs_test2 > umbral_optimo, 1, 0)
# Convertimos a Factor para caret (asegurando niveles 0 y 1)
f_pred_train2 <- factor(pred_class_train2, levels = c(0, 1))
f_pred_test2  <- factor(pred_class_test2, levels = c(0, 1))
f_real_train2 <- factor(train2$Exited, levels = c(0, 1))
f_real_test2  <- factor(test2$Exited, levels = c(0, 1))
# Matrices de Confusión
cm_train <- confusionMatrix(f_pred_train2, f_real_train2, positive = "1", mode = "prec_recall")
cm_test  <- confusionMatrix(f_pred_test2, f_real_test2, positive = "1", mode = "prec_recall")
# Tabla Resumen
resultados <- data.frame(
Dataset = c("Train2", "Test2"),
Accuracy = c(cm_train$overall["Accuracy"], cm_test$overall["Accuracy"]),
Precision = c(cm_train$byClass["Precision"], cm_test$byClass["Precision"]),
Recall = c(cm_train$byClass["Sensitivity"], cm_test$byClass["Sensitivity"]),
F1_Score = c(cm_train$byClass["F1"], cm_test$byClass["F1"])
)
print(resultados)
cat("El umbral optimizado es:", umbral_optimo, "\n")
#####################################################
### 7. CÁLCULO DE KPIS (TRAIN2 VS TEST2)
#####################################################
umbral_optimo<-0.47
# Obtenemos predicciones también para train2 para ver si hay overfitting
probs_train2 <- predict(modelo_xgb, dtrain2)
# Convertimos probabilidad a clase usando el umbral optimizado
pred_class_train2 <- ifelse(probs_train2 > umbral_optimo, 1, 0)
pred_class_test2  <- ifelse(probs_test2 > umbral_optimo, 1, 0)
# Convertimos a Factor para caret (asegurando niveles 0 y 1)
f_pred_train2 <- factor(pred_class_train2, levels = c(0, 1))
f_pred_test2  <- factor(pred_class_test2, levels = c(0, 1))
f_real_train2 <- factor(train2$Exited, levels = c(0, 1))
f_real_test2  <- factor(test2$Exited, levels = c(0, 1))
# Matrices de Confusión
cm_train <- confusionMatrix(f_pred_train2, f_real_train2, positive = "1", mode = "prec_recall")
cm_test  <- confusionMatrix(f_pred_test2, f_real_test2, positive = "1", mode = "prec_recall")
# Tabla Resumen
resultados <- data.frame(
Dataset = c("Train2", "Test2"),
Accuracy = c(cm_train$overall["Accuracy"], cm_test$overall["Accuracy"]),
Precision = c(cm_train$byClass["Precision"], cm_test$byClass["Precision"]),
Recall = c(cm_train$byClass["Sensitivity"], cm_test$byClass["Sensitivity"]),
F1_Score = c(cm_train$byClass["F1"], cm_test$byClass["F1"])
)
print(resultados)
mydata <- data_reducida
#####################################################
# PREPARACIÓN
#####################################################
# Separar Train y Test (para Kaggle, Exited vacía)
train <- subset(mydata, group == "train")
test  <- subset(mydata, group == "test")
# Guardar ID para submission y eliminar variables innecesarias para el modelo
test_submission_id <- test$ID
variables_eliminar <- c("group", "Surname", "ID")
train <- train[, !names(train) %in% variables_eliminar]
test  <- test[, !names(test) %in% c("group", "Surname", "ID")]
#####################################################
### FEATURE ENGINEERING
#####################################################
# Creamos HasBalance porque los que tienen saldo se van mas
# XGBoost prefiere números: 1 si tiene saldo, 0 si no.
train$HasBalance <- ifelse(train$Balance > 0, 1, 0)
test$HasBalance  <- ifelse(test$Balance > 0, 1, 0)
train$Balance<-NULL
test$Balance<-NULL
# Convertir la variable objetivo a numérica 0/1 para XGBoost
# "Yes" o "1" es la clase positiva.
train$Exited <- ifelse(train$Exited == "Yes" | train$Exited == "1", 1, 0)
#####################################################
### 3. PARTICIÓN INTERNA (TRAIN2 / TEST2)
#####################################################
set.seed(689)
index <- createDataPartition(train$Exited, p = 0.7, list = FALSE)
train2 <- train[index, ]
test2  <- train[-index, ]
# Separamos predictores de la variable objetivo
predictors_train2 <- train2[, !names(train2) %in% "Exited"]
predictors_test2  <- test2[, !names(test2) %in% "Exited"]
predictors_kaggle <- test[, !names(test) %in% "Exited"] # El test de Kaggle no tiene Exited
# Creamos el esquema de transformación
dummy_obj <- dummyVars(~ ., data = predictors_train2, fullRank = FALSE)
# Aplicamos el esquema a los 3 conjuntos de datos
mat_train2  <- predict(dummy_obj, newdata = predictors_train2)
mat_test2   <- predict(dummy_obj, newdata = predictors_test2)
mat_kaggle  <- predict(dummy_obj, newdata = predictors_kaggle)
# Convertimos a formato nativo de XGBoost (DMatrix)
# test2 y train2 llevan etiqueta (label), kaggle no.
dtrain2 <- xgb.DMatrix(data = mat_train2, label = train2$Exited)
dtest2  <- xgb.DMatrix(data = mat_test2, label = test2$Exited)
dkaggle <- xgb.DMatrix(data = mat_kaggle)
#####################################################
### 5. ENTRENAMIENTO XGBOOST CON CV
#####################################################
# Configuración para subir el F1 (Atención a scale_pos_weight)
params <- list(
objective = "binary:logistic",
eval_metric = "auc",
eta = 0.1,              # Aprendizaje lento para evitar overfitting
max_depth = 2,           # Árboles no muy profundos
subsample = 0.7,
colsample_bytree = 1,
scale_pos_weight = 4     # CLAVE: Compensar desbalanceo (aprox 80/20 ratio)
)
set.seed(689)
# Cross Validation para encontrar el número óptimo de rondas
cv_res <- xgb.cv(
params = params,
data = dtrain2,
nrounds = 1000,
nfold = 5,
stratified = TRUE,       # CLAVE: Evita el error de "dataset empty"
early_stopping_rounds = 50,
print_every_n = 50,
maximize = TRUE
)
# Entrenar modelo final con la mejor iteración encontrada
modelo_xgb <- xgb.train(
params = params,
data = dtrain2,
nrounds = cv_res$best_iteration
)
#####################################################
### 6. EVALUACIÓN Y UMBRAL ÓPTIMO (TEST2)
#####################################################
# Predecimos probabilidades sobre la validación interna
probs_test2 <- predict(modelo_xgb, dtest2)
# Curva ROC para buscar el mejor punto de corte
roc_obj <- roc(test2$Exited, probs_test2)
# Buscamos el umbral que maximiza la suma de Sensibilidad y Especificidad
coords_optimas <- coords(roc_obj, "best",
ret = c("threshold", "sensitivity", "specificity"),
best.method = "closest.topleft")
umbral_optimo <- coords_optimas$threshold
cat("El umbral optimizado es:", umbral_optimo, "\n")
################## GRAFICO ROC ########################
plot(roc_obj, print.auc = TRUE, print.thres = "best", col="blue", main="ROC Curve (Validation)")
#####################################################
### 7. CÁLCULO DE KPIS (TRAIN2 VS TEST2)
#####################################################
umbral_optimo<-0.47
umbral_optimo <- coords_optimas$threshold
# Obtenemos predicciones también para train2 para ver si hay overfitting
probs_train2 <- predict(modelo_xgb, dtrain2)
# Convertimos probabilidad a clase usando el umbral optimizado
pred_class_train2 <- ifelse(probs_train2 > umbral_optimo, 1, 0)
pred_class_test2  <- ifelse(probs_test2 > umbral_optimo, 1, 0)
# Convertimos a Factor para caret (asegurando niveles 0 y 1)
f_pred_train2 <- factor(pred_class_train2, levels = c(0, 1))
f_pred_test2  <- factor(pred_class_test2, levels = c(0, 1))
f_real_train2 <- factor(train2$Exited, levels = c(0, 1))
f_real_test2  <- factor(test2$Exited, levels = c(0, 1))
# Matrices de Confusión
cm_train <- confusionMatrix(f_pred_train2, f_real_train2, positive = "1", mode = "prec_recall")
cm_test  <- confusionMatrix(f_pred_test2, f_real_test2, positive = "1", mode = "prec_recall")
# Tabla Resumen
resultados <- data.frame(
Dataset = c("Train2", "Test2"),
Accuracy = c(cm_train$overall["Accuracy"], cm_test$overall["Accuracy"]),
Precision = c(cm_train$byClass["Precision"], cm_test$byClass["Precision"]),
Recall = c(cm_train$byClass["Sensitivity"], cm_test$byClass["Sensitivity"]),
F1_Score = c(cm_train$byClass["F1"], cm_test$byClass["F1"])
)
print(resultados)
knitr::opts_chunk$set(echo = TRUE)
train <- subset(mydata, group == "train")
test  <- subset(mydata, group == "test")
test_submission_id <- test$ID
variables_eliminar <- c("group", "Surname", "ID")
train <- train[, !names(train) %in% variables_eliminar]
test  <- test[, !names(test) %in% variables_eliminar]
train$HasBalance <- ifelse(train$Balance > 0, 1, 0)
test$HasBalance  <- ifelse(test$Balance > 0, 1, 0)
train$Exited <- ifelse(train$Exited == "Yes" | train$Exited == "1", 1, 0)
params <- list(
objective = "binary:logistic",
eval_metric = "auc",
eta = 0.05,
max_depth = 4,
subsample = 0.7,
colsample_bytree = 0.7,
scale_pos_weight = 4
)
train <- subset(mydata, group == "train")
test  <- subset(mydata, group == "test")
test_submission_id <- test$ID
variables_eliminar <- c("group", "Surname", "ID")
train <- train[, !names(train) %in% variables_eliminar]
test  <- test[, !names(test) %in% variables_eliminar]
train$HasBalance <- ifelse(train$Balance > 0, 1, 0)
test$HasBalance  <- ifelse(test$Balance > 0, 1, 0)
train$Balance <- ifelse(train$Balance > 0, 1, 0)
test$Balance  <- ifelse(test$Balance > 0, 1, 0)
train$Exited <- ifelse(train$Exited == "Yes" | train$Exited == "1", 1, 0)
params <- list(
objective = "binary:logistic",
eval_metric = "auc",
eta = 0.05,
max_depth = 4,
subsample = 0.7,
colsample_bytree = 0.7,
scale_pos_weight = 4
)
semillas <- 1001:1500
f1_train <- numeric(length(semillas))
f1_test  <- numeric(length(semillas))
### NUEVO
recall_train <- numeric(length(semillas))
recall_test  <- numeric(length(semillas))
threshold_opt <- numeric(length(semillas))
for (i in seq_along(semillas)) {
set.seed(semillas[i])
index <- createDataPartition(train$Exited, p = 0.7, list = FALSE)
train2 <- train[index, ]
test2  <- train[-index, ]
predictors_train2 <- train2[, !names(train2) %in% "Exited"]
predictors_test2  <- test2[, !names(test2) %in% "Exited"]
dummy_obj <- dummyVars(~ ., data = predictors_train2, fullRank = FALSE)
mat_train2 <- predict(dummy_obj, predictors_train2)
mat_test2  <- predict(dummy_obj, predictors_test2)
dtrain2 <- xgb.DMatrix(mat_train2, label = train2$Exited)
dtest2  <- xgb.DMatrix(mat_test2,  label = test2$Exited)
cv_res <- xgb.cv(
params = params,
data = dtrain2,
nrounds = 1000,
nfold = 5,
stratified = TRUE,
early_stopping_rounds = 50,
verbose = 0,
maximize = TRUE
)
modelo_xgb <- xgb.train(
params = params,
data = dtrain2,
nrounds = cv_res$best_iteration
)
probs_train2 <- predict(modelo_xgb, dtrain2)
probs_test2  <- predict(modelo_xgb, dtest2)
roc_obj <- roc(test2$Exited, probs_test2, quiet = TRUE)
coords_optimas <- coords(
roc_obj, "best",
ret = c("threshold", "sensitivity", "specificity"),
best.method = "closest.topleft"
)
umbral_optimo <- coords_optimas$threshold[1]
threshold_opt[i] <- umbral_optimo
pred_class_train2 <- ifelse(probs_train2 > umbral_optimo, 1, 0)
pred_class_test2  <- ifelse(probs_test2  > umbral_optimo, 1, 0)
f_pred_train2 <- factor(pred_class_train2, levels = c(0, 1))
f_pred_test2  <- factor(pred_class_test2,  levels = c(0, 1))
f_real_train2 <- factor(train2$Exited, levels = c(0, 1))
f_real_test2  <- factor(test2$Exited,  levels = c(0, 1))
cm_train <- confusionMatrix(
f_pred_train2, f_real_train2,
positive = "1", mode = "prec_recall"
)
cm_test <- confusionMatrix(
f_pred_test2, f_real_test2,
positive = "1", mode = "prec_recall"
)
f1_train[i] <- cm_train$byClass["F1"]
f1_test[i]  <- cm_test$byClass["F1"]
### NUEVO
recall_train[i] <- cm_train$byClass["Recall"]
recall_test[i]  <- cm_test$byClass["Recall"]
cat("Semilla:", semillas[i],
"| F1 Train:", round(f1_train[i], 4),
"| F1 Test:", round(f1_test[i], 4),
"| Recall Test:", round(recall_test[i], 4),
"| Threshold:", round(umbral_optimo, 4), "\n")
}
df <- data.frame(
semilla = semillas,
F1_train = f1_train,
F1_test  = f1_test,
Recall_train = recall_train,
Recall_test  = recall_test,
Threshold_optimo = threshold_opt
)
ranking_final <- df[order(-df$F1_test), ][1:30, ]
ranking_final
