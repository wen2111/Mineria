recall_test[i]  <- cm_test$byClass["Recall"]
cat("Semilla:", semillas[i],
"| F1 Train:", round(f1_train[i], 4),
"| F1 Test:", round(f1_test[i], 4),
"| Recall Test:", round(recall_test[i], 4),
"| Threshold:", round(umbral_optimo, 4), "\n")
}
###############################33
mydata <- data_reducida
# Crear rangos personalizados
mydata <- mydata %>%
mutate(
AgeC = cut(
Age,
breaks = c(0,20,40, 50, 60, 70,80, 100),
right = FALSE,
labels = c("0-20","20-40" ,"40-50", "50-60", "60-70", "70-80","80-100")
)
)
mydata$Age<-NULL
mydata$group<-NULL
#dummifico data reducido
x<-mydata[,-3] #quito la respuesta
x <- x[, c(1:4, 6)]
x <- fastDummies::dummy_cols(x,
remove_first_dummy = TRUE,
remove_selected_columns = TRUE)
x$Balance<-mydata[,6] # adjunto las numericas
x$Exited<-mydata$Exited # añado la respuesta
mydata<-x
###################################################################
# SEPARAR TRAIN Y TEST
train <- mydata[1:7000,]
test <- mydata[7001:10000,]  # 3000 obs
train$HasBalance <- ifelse(train$Balance > 0, 1, 0)
test$HasBalance  <- ifelse(test$Balance > 0, 1, 0)
train$Balance <- ifelse(train$Balance > 0, 1, 0)
test$Balance  <- ifelse(test$Balance > 0, 1, 0)
train$Exited <- ifelse(train$Exited == "Yes" | train$Exited == "1", 1, 0)
params <- list(
objective = "binary:logistic",
eval_metric = "auc",
eta = 0.05,
max_depth = 4,
subsample = 0.7,
colsample_bytree = 0.7,
scale_pos_weight = 4
)
semillas <- 1001:1500
f1_train <- numeric(length(semillas))
f1_test  <- numeric(length(semillas))
### NUEVO
recall_train <- numeric(length(semillas))
recall_test  <- numeric(length(semillas))
threshold_opt <- numeric(length(semillas))
for (i in seq_along(semillas)) {
set.seed(semillas[i])
index <- createDataPartition(train$Exited, p = 0.7, list = FALSE)
train2 <- train[index, ]
test2  <- train[-index, ]
predictors_train2 <- train2[, !names(train2) %in% "Exited"]
predictors_test2  <- test2[, !names(test2) %in% "Exited"]
dummy_obj <- dummyVars(~ ., data = predictors_train2, fullRank = FALSE)
mat_train2 <- predict(dummy_obj, predictors_train2)
mat_test2  <- predict(dummy_obj, predictors_test2)
dtrain2 <- xgb.DMatrix(mat_train2, label = train2$Exited)
dtest2  <- xgb.DMatrix(mat_test2,  label = test2$Exited)
cv_res <- xgb.cv(
params = params,
data = dtrain2,
nrounds = 1000,
nfold = 5,
stratified = TRUE,
early_stopping_rounds = 50,
verbose = 0,
maximize = TRUE
)
modelo_xgb <- xgb.train(
params = params,
data = dtrain2,
nrounds = cv_res$best_iteration
)
probs_train2 <- predict(modelo_xgb, dtrain2)
probs_test2  <- predict(modelo_xgb, dtest2)
roc_obj <- roc(test2$Exited, probs_test2, quiet = TRUE)
coords_optimas <- coords(
roc_obj, "best",
ret = c("threshold", "sensitivity", "specificity"),
best.method = "closest.topleft"
)
umbral_optimo <- coords_optimas$threshold[1]
threshold_opt[i] <- umbral_optimo
pred_class_train2 <- ifelse(probs_train2 > umbral_optimo, 1, 0)
pred_class_test2  <- ifelse(probs_test2  > umbral_optimo, 1, 0)
f_pred_train2 <- factor(pred_class_train2, levels = c(0, 1))
f_pred_test2  <- factor(pred_class_test2,  levels = c(0, 1))
f_real_train2 <- factor(train2$Exited, levels = c(0, 1))
f_real_test2  <- factor(test2$Exited,  levels = c(0, 1))
#x
cm_train <- confusionMatrix(
f_pred_train2, f_real_train2,
positive = "1", mode = "prec_recall"
)
cm_test <- confusionMatrix(
f_pred_test2, f_real_test2,
positive = "1", mode = "prec_recall"
)
f1_train[i] <- cm_train$byClass["F1"]
f1_test[i]  <- cm_test$byClass["F1"]
### NUEVO
recall_train[i] <- cm_train$byClass["Recall"]
recall_test[i]  <- cm_test$byClass["Recall"]
cat("Semilla:", semillas[i],
"| F1 Train:", round(f1_train[i], 4),
"| F1 Test:", round(f1_test[i], 4),
"| Recall Test:", round(recall_test[i], 4),
"| Threshold:", round(umbral_optimo, 4), "\n")
}
###############################33
mydata <- data_reducida
# Crear rangos personalizados
mydata <- mydata %>%
mutate(
AgeC = cut(
Age,
breaks = c(0,20,40, 50, 60, 70,80, 100),
right = FALSE,
labels = c("0-20","20-40" ,"40-50", "50-60", "60-70", "70-80","80-100")
)
)
mydata$Age<-NULL
mydata <- data_reducida
#dummifico data reducido
x<-mydata[,-3] #quito la respuesta
x<-x[,1:4] # cojo solo las cat
x <- fastDummies::dummy_cols(x,
remove_first_dummy = TRUE,
remove_selected_columns = TRUE)
x<-cbind(x,mydata[,6:7]) # adjunto las numericas
x$Exited<-mydata$Exited # añado la respuesta
mydata<-x
mydata$hasB<-ifelse(mydata$Balance==0,0,1)
mydata$Balance<-NULL
# SEPARAR TRAIN Y TEST
train <- mydata[1:7000,]
test <- mydata[7001:10000,]  # 3000 obs
# LABELS PARA EXITED
train$Exited <- factor(train$Exited,
levels = c("0","1"),
labels = c("No","Yes"))
###############################33
mydata <- data_reducida
# Crear rangos personalizados
mydata <- mydata %>%
mutate(
AgeC = cut(
Age,
breaks = c(0,20,40, 50, 60, 70,80, 100),
right = FALSE,
labels = c("0-20","20-40" ,"40-50", "50-60", "60-70", "70-80","80-100")
)
)
mydata$Age<-NULL
mydata$group<-NULL
#dummifico data reducido
x<-mydata[,-3] #quito la respuesta
x <- x[, c(1:4, 6)]
x <- fastDummies::dummy_cols(x,
remove_first_dummy = TRUE,
remove_selected_columns = TRUE)
x$Balance<-mydata[,6] # adjunto las numericas
x$Exited<-mydata$Exited # añado la respuesta
mydata<-x
mydata$hasB<-ifelse(mydata$Balance==0,0,1)
# SEPARAR TRAIN Y TEST
train <- mydata[1:7000,]
test <- mydata[7001:10000,]  # 3000 obs
# LABELS PARA EXITED
train$Exited <- factor(train$Exited,
levels = c("0","1"),
labels = c("No","Yes"))
# PARTICION TRAIN2/TEST2
semillas <- sample(1:1000, 100)
f1_train <- numeric(length(semillas))
f1_test  <- numeric(length(semillas))
for (i in seq_along(semillas)) {
set.seed(semillas[i])
index <- createDataPartition(train$Exited, p = 0.7, list = FALSE)
train2 <- train[index, ] # train interno
test2  <- train[-index, ] # test interno
library(MLmetrics)
f1_recall_summary <- function(data, lev = NULL, model = NULL) {
precision <- Precision(y_true = data$obs, y_pred = data$pred, positive = "Yes")
recall <- Recall(y_true = data$obs, y_pred = data$pred, positive = "Yes")
f1 <- F1_Score(y_true = data$obs, y_pred = data$pred, positive = "Yes")
c(F1 = f1, Recall = recall, Precision = precision)
}
ctrl_boot_auc <- trainControl(method = "cv",
number = 5 ,
classProbs = TRUE,
summaryFunction = f1_recall_summary
)
xgb_grid <- expand.grid(
nrounds = 150 ,
max_depth = 2 ,
eta = 0.4,
gamma = 3,
colsample_bytree = 0.8,
min_child_weight = 1,
subsample = 0.7
)
fit_tuning <- train(
Exited ~ .,
data = train2,
method = "xgbTree",
metric = "F1",
trControl = ctrl_boot_auc,
tuneGrid = xgb_grid,
preProcess = "scale",
verbosity = 0
)
# Predicciones probabilísticas
train_pred_prob <- predict(fit_tuning, newdata = train2, type = "prob")
test_pred_prob  <- predict(fit_tuning, newdata = test2,  type = "prob")
#best p
f1_score <- function(y_true, y_pred) {
tp <- sum(y_true == "Yes" & y_pred == "Yes")
fp <- sum(y_true == "No"  & y_pred == "Yes")
fn <- sum(y_true == "Yes" & y_pred == "No")
precision <- tp / (tp + fp)
recall    <- tp / (tp + fn)
2 * precision * recall / (precision + recall)
}
thresholds <- seq(0.01, 0.99, by = 0.01)
f1_values <- sapply(thresholds, function(t) {
pred <- ifelse(train_pred_prob$Yes > t, "Yes", "No")
f1_score(train2$Exited, pred)
})
best_threshold <- thresholds[which.max(f1_values)]
train_pred_cut <- ifelse(train_pred_prob$Yes > best_threshold, "Yes", "No")
test_pred_cut  <- ifelse(test_pred_prob$Yes > best_threshold, "Yes", "No")
# Pasamos a clase: yes/no
train_pred_cut <- factor(train_pred_cut, levels = c("No","Yes"))
test_pred_cut  <- factor(test_pred_cut,  levels = c("No","Yes"))
# Matrices de confusión
conf_train <- confusionMatrix(train_pred_cut, train2$Exited,positive = "Yes")
conf_test  <- confusionMatrix(test_pred_cut, test2$Exited,positive = "Yes")
# F1-score function
f1_score <- function(cm){
precision <- cm$byClass["Precision"]
recall    <- cm$byClass["Sensitivity"]
f1 <- 2 * (precision * recall) / (precision + recall)
return(as.numeric(f1))
}
f1_train[i] <- f1_score(conf_train)
f1_test[i]  <- f1_score(conf_test)
cat("Semilla:", semillas[i],
"| F1 Train:", round(f1_train[i], 4),
"| F1 Test:", round(f1_test[i], 4), "\n")
}
###############################33
mydata <- data_reducida
# Crear rangos personalizados
mydata <- mydata %>%
mutate(
AgeC = cut(
Age,
breaks = c(0,20,40, 50, 60, 70,80, 100),
right = FALSE,
labels = c("0-20","20-40" ,"40-50", "50-60", "60-70", "70-80","80-100")
)
)
mydata$Age<-NULL
mydata$group<-NULL
#dummifico data reducido
x<-mydata[,-3] #quito la respuesta
x <- x[, c(1:4, 6)]
x <- fastDummies::dummy_cols(x,
remove_first_dummy = TRUE,
remove_selected_columns = TRUE)
x$Balance<-mydata[,6] # adjunto las numericas
x$Exited<-mydata$Exited # añado la respuesta
mydata<-x
mydata$hasB<-ifelse(mydata$Balance==0,0,1)
mydata$Balance<-NULL
###################################################################
# SEPARAR TRAIN Y TEST
train <- mydata[1:7000,]
test <- mydata[7001:10000,]  # 3000 obs
###############################33
mydata <- data_reducida
# Crear rangos personalizados
mydata <- mydata %>%
mutate(
AgeC = cut(
Age,
breaks = c(0,20,40, 50, 60, 70,80, 100),
right = FALSE,
labels = c("0-20","20-40" ,"40-50", "50-60", "60-70", "70-80","80-100")
)
)
mydata$Age<-NULL
mydata$group<-NULL
#dummifico data reducido
x<-mydata[,-3] #quito la respuesta
x <- x[, c(1:4, 6)]
x <- fastDummies::dummy_cols(x,
remove_first_dummy = TRUE,
remove_selected_columns = TRUE)
x$Balance<-mydata[,6] # adjunto las numericas
x$Exited<-mydata$Exited # añado la respuesta
mydata<-x
mydata$hasB<-ifelse(mydata$Balance==0,0,1)
###################################################################
# SEPARAR TRAIN Y TEST
train <- mydata[1:7000,]
test <- mydata[7001:10000,]  # 3000 obs
# LABELS PARA EXITED
train$Exited <- factor(train$Exited,
levels = c("0","1"),
labels = c("No","Yes"))
# PARTICION TRAIN2/TEST2
semillas <- sample(1:1000, 100)
f1_train <- numeric(length(semillas))
f1_test  <- numeric(length(semillas))
for (i in seq_along(semillas)) {
set.seed(semillas[i])
index <- createDataPartition(train$Exited, p = 0.7, list = FALSE)
train2 <- train[index, ] # train interno
test2  <- train[-index, ] # test interno
library(MLmetrics)
f1_recall_summary <- function(data, lev = NULL, model = NULL) {
precision <- Precision(y_true = data$obs, y_pred = data$pred, positive = "Yes")
recall <- Recall(y_true = data$obs, y_pred = data$pred, positive = "Yes")
f1 <- F1_Score(y_true = data$obs, y_pred = data$pred, positive = "Yes")
c(F1 = f1, Recall = recall, Precision = precision)
}
ctrl_boot_auc <- trainControl(method = "cv",
number = 5 ,
classProbs = TRUE,
summaryFunction = f1_recall_summary
)
xgb_grid <- expand.grid(
nrounds = 700,
max_depth = 5,
eta = 0.1,
gamma = 3 ,
colsample_bytree = 0.8,
min_child_weight = 1,
subsample = 0.5
)
fit_tuning <- train(
Exited ~ .,
data = train2,
method = "xgbTree",
metric = "F1",
trControl = ctrl_boot_auc,
tuneGrid = xgb_grid,
preProcess = "scale",
verbosity = 0
)
# Predicciones probabilísticas
train_pred_prob <- predict(fit_tuning, newdata = train2, type = "prob")
test_pred_prob  <- predict(fit_tuning, newdata = test2,  type = "prob")
#best p
f1_score <- function(y_true, y_pred) {
tp <- sum(y_true == "Yes" & y_pred == "Yes")
fp <- sum(y_true == "No"  & y_pred == "Yes")
fn <- sum(y_true == "Yes" & y_pred == "No")
precision <- tp / (tp + fp)
recall    <- tp / (tp + fn)
2 * precision * recall / (precision + recall)
}
thresholds <- seq(0.01, 0.99, by = 0.01)
f1_values <- sapply(thresholds, function(t) {
pred <- ifelse(train_pred_prob$Yes > t, "Yes", "No")
f1_score(train2$Exited, pred)
})
best_threshold <- thresholds[which.max(f1_values)]
train_pred_cut <- ifelse(train_pred_prob$Yes > best_threshold, "Yes", "No")
test_pred_cut  <- ifelse(test_pred_prob$Yes > best_threshold, "Yes", "No")
# Pasamos a clase: yes/no
train_pred_cut <- factor(train_pred_cut, levels = c("No","Yes"))
test_pred_cut  <- factor(test_pred_cut,  levels = c("No","Yes"))
# Matrices de confusión
conf_train <- confusionMatrix(train_pred_cut, train2$Exited,positive = "Yes")
conf_test  <- confusionMatrix(test_pred_cut, test2$Exited,positive = "Yes")
# F1-score function
f1_score <- function(cm){
precision <- cm$byClass["Precision"]
recall    <- cm$byClass["Sensitivity"]
f1 <- 2 * (precision * recall) / (precision + recall)
return(as.numeric(f1))
}
f1_train[i] <- f1_score(conf_train)
f1_test[i]  <- f1_score(conf_test)
cat("Semilla:", semillas[i],
"| F1 Train:", round(f1_train[i], 4),
"| F1 Test:", round(f1_test[i], 4), "\n")
}
###############################33
mydata <- data_reducida
# Crear rangos personalizados
mydata <- mydata %>%
mutate(
AgeC = cut(
Age,
breaks = c(0,20,40, 50, 60, 70,80, 100),
right = FALSE,
labels = c("0-20","20-40" ,"40-50", "50-60", "60-70", "70-80","80-100")
)
)
mydata$Age<-NULL
mydata$group<-NULL
#dummifico data reducido
x<-mydata[,-3] #quito la respuesta
x <- x[, c(1:4, 6)]
x <- fastDummies::dummy_cols(x,
remove_first_dummy = TRUE,
remove_selected_columns = TRUE)
x$Balance<-mydata[,6] # adjunto las numericas
x$Exited<-mydata$Exited # añado la respuesta
mydata<-x
mydata$hasB<-ifelse(mydata$Balance==0,0,1)
mydata$Balance<-NULL
###################################################################
# SEPARAR TRAIN Y TEST
train <- mydata[1:7000,]
test <- mydata[7001:10000,]  # 3000 obs
# LABELS PARA EXITED
train$Exited <- factor(train$Exited,
levels = c("0","1"),
labels = c("No","Yes"))
# PARTICION TRAIN2/TEST2
semillas <- sample(1:1000, 100)
f1_train <- numeric(length(semillas))
f1_test  <- numeric(length(semillas))
for (i in seq_along(semillas)) {
set.seed(semillas[i])
index <- createDataPartition(train$Exited, p = 0.7, list = FALSE)
train2 <- train[index, ] # train interno
test2  <- train[-index, ] # test interno
library(MLmetrics)
f1_recall_summary <- function(data, lev = NULL, model = NULL) {
precision <- Precision(y_true = data$obs, y_pred = data$pred, positive = "Yes")
recall <- Recall(y_true = data$obs, y_pred = data$pred, positive = "Yes")
f1 <- F1_Score(y_true = data$obs, y_pred = data$pred, positive = "Yes")
c(F1 = f1, Recall = recall, Precision = precision)
}
ctrl_boot_auc <- trainControl(method = "cv",
number = 5 ,
classProbs = TRUE,
summaryFunction = f1_recall_summary
)
xgb_grid <- expand.grid(
nrounds = 700,
max_depth = 5,
eta = 0.1,
gamma = 3 ,
colsample_bytree = 0.8,
min_child_weight = 1,
subsample = 0.5
)
fit_tuning <- train(
Exited ~ .,
data = train2,
method = "xgbTree",
metric = "F1",
trControl = ctrl_boot_auc,
tuneGrid = xgb_grid,
preProcess = "scale",
verbosity = 0
)
# Predicciones probabilísticas
train_pred_prob <- predict(fit_tuning, newdata = train2, type = "prob")
test_pred_prob  <- predict(fit_tuning, newdata = test2,  type = "prob")
#best p
f1_score <- function(y_true, y_pred) {
tp <- sum(y_true == "Yes" & y_pred == "Yes")
fp <- sum(y_true == "No"  & y_pred == "Yes")
fn <- sum(y_true == "Yes" & y_pred == "No")
precision <- tp / (tp + fp)
recall    <- tp / (tp + fn)
2 * precision * recall / (precision + recall)
}
thresholds <- seq(0.01, 0.99, by = 0.01)
f1_values <- sapply(thresholds, function(t) {
pred <- ifelse(train_pred_prob$Yes > t, "Yes", "No")
f1_score(train2$Exited, pred)
})
best_threshold <- thresholds[which.max(f1_values)]
train_pred_cut <- ifelse(train_pred_prob$Yes > best_threshold, "Yes", "No")
test_pred_cut  <- ifelse(test_pred_prob$Yes > best_threshold, "Yes", "No")
# Pasamos a clase: yes/no
train_pred_cut <- factor(train_pred_cut, levels = c("No","Yes"))
test_pred_cut  <- factor(test_pred_cut,  levels = c("No","Yes"))
# Matrices de confusión
conf_train <- confusionMatrix(train_pred_cut, train2$Exited,positive = "Yes")
conf_test  <- confusionMatrix(test_pred_cut, test2$Exited,positive = "Yes")
# F1-score function
f1_score <- function(cm){
precision <- cm$byClass["Precision"]
recall    <- cm$byClass["Sensitivity"]
f1 <- 2 * (precision * recall) / (precision + recall)
return(as.numeric(f1))
}
f1_train[i] <- f1_score(conf_train)
f1_test[i]  <- f1_score(conf_test)
cat("Semilla:", semillas[i],
"| F1 Train:", round(f1_train[i], 4),
"| F1 Test:", round(f1_test[i], 4), "\n")
}
