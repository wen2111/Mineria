boot data_reducida
glm cloglog con scale
 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2581633 0.7418367 0.4115983           0.573399   0.7858430 0.4792096
2   Test2  0.2709524 0.7290476 0.3912338           0.554023   0.7747748 0.4586108

glm cauchy con scale
  Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2608163 0.7391837 0.4075896          0.5714286   0.7830116 0.4757998
2   Test2  0.2761905 0.7238095 0.3851030          0.5586207   0.7669670 0.4559099

glm probitcon scale
 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2546939 0.7453061 0.4122080          0.5389163   0.7992278 0.4671221
2   Test2  0.2566667 0.7433333 0.4087719          0.5356322   0.7975976 0.4636816

glm logit con scale
 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2591837 0.7408163 0.4076756          0.5546798   0.7894466 0.4699499
2   Test2  0.2633333 0.7366667 0.4006734          0.5471264   0.7861862 0.4625850

cv
glm logit con scale
 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2591837 0.7408163 0.4076756          0.5546798   0.7894466 0.4699499
2   Test2  0.2633333 0.7366667 0.4006734          0.5471264   0.7861862 0.4625850

da lo mismo y ademas se tarda menos. por lo tanto aplicar cv. sin scale tmb me da lo mismo.

## parece que funciona mejor el reducido solo.

# con data_reducida_plus logit <- no mejora el test 

 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2700000 0.7300000  0.400000          0.6068966   0.7621622 0.4821918
2   Test2  0.2885714 0.7114286  0.374817          0.5885057   0.7435435 0.4579606


cloglog

 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.3222449 0.6777551 0.3552361          0.6817734   0.6767053 0.4670942
2   Test2  0.3357143 0.6642857 0.3426573          0.6758621   0.6612613 0.4547564


XGBOOST con dummy 0.7 MEJOR SIN HACER NADA DE BALANCEO p=0.29

 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2136735 0.7863265 0.4857398          0.5369458   0.8514801 0.5100608
2   Test2  0.2185714 0.7814286 0.4757085          0.5402299   0.8444444 0.5059203

0.8 train CON DUMMY

 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2064286 0.7935714 0.5017452          0.4956897   0.8713964 0.4986990
2   Test2  0.2042857 0.7957143 0.5069930          0.5000000   0.8729730 0.5034722

0.8 train SIN DUMMY
  Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2064286 0.7935714 0.5017452          0.4956897   0.8713964 0.4986990
2   Test2  0.2042857 0.7957143 0.5069930          0.5000000   0.8729730 0.5034722


con balanceo smote 0.8 train overfitting

 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.1684911 0.8315089 0.7557384          0.7521552   0.8729730 0.7539425
2   Test2  0.2071429 0.7928571 0.5000000          0.5137931   0.8657658 0.5068027


0.7 train overfitting

 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.1633136 0.8366864 0.7860215          0.7201970   0.8975547 0.7516710
2   Test2  0.1990476 0.8009524 0.5210918          0.4827586   0.8840841 0.5011933

con smote hecho fuera <- overfitting

con smote interno train
Dataset Error_rate Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2   0.215102 0.784898 0.4810863          0.4886700   0.8622909 0.4848485
2   Test2   0.220000 0.780000 0.4700665          0.4873563   0.8564565 0.4785553

con up <- MAL PORQUE UN P MUY ALTO<- SUEPR RARO
  Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2046939 0.7953061 0.5060241          0.4965517   0.8733591 0.5012432
2   Test2  0.2095238 0.7904762 0.4943311          0.5011494   0.8660661 0.4977169

###############################################333
xgbopots datareduido plus con p=0.2071429
 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2389796 0.7610204 0.4476510          0.6571429   0.7881596 0.5325349
2   Test2  0.2738095 0.7261905 0.3952096          0.6068966   0.7573574 0.4786945

0.5108471
data reducido
Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2653061 0.7346939 0.4157303          0.6926108   0.7456885 0.5195861
2   Test2  0.2957143 0.7042857 0.3769841          0.6551724   0.7171171 0.4785894
0.5108471
observem que tot i que el f1 es simialar, amb el data set reduit nomes obtenim un recall mes elevat.

con famd<- shit
Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2010204 0.7989796 0.5092478          0.8137931   0.7951094 0.6264695
2   Test2  0.3128571 0.6871429 0.3487738          0.5885057   0.7129129 0.4379812

con scale_pos_weigth <- SHIT

Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.1500000 0.8500000 0.7447552          0.4197044   0.9624196 0.5368620
2   Test2  0.1947619 0.8052381 0.5492424          0.3333333   0.9285285 0.4148784

RANDOMFOREST data imputado con p=0.2

Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.1765306 0.8234694 0.6409774          0.3359606   0.9508366 0.4408533
2   Test2  0.1909524 0.8090476 0.5720339          0.3103448   0.9393393 0.4023845

con p=media de la distrib del test=0.06218
 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.1965306 0.8034694 0.5251451          0.5349754   0.8736165 0.5300146
2   Test2  0.2228571 0.7771429 0.4642082          0.4919540   0.8516517 0.4776786

con ptrain<-probar 0.06079
 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.1967347 0.8032653 0.5243089          0.5418719   0.8715573 0.5329457
2   Test2  0.2242857 0.7757143 0.4615385          0.4965517   0.8486486 0.4784053
con la mediana <- probar
Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.3261224 0.6738776 0.3683973          0.8039409    0.639897 0.5052632
2   Test2  0.3857143 0.6142857 0.3119358          0.7149425    0.587988 0.4343575

#data reducida con p= media del ptrain

 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.1918367 0.8081633 0.5468165          0.4315271   0.9065637 0.4823789
2   Test2  0.1957143 0.8042857 0.5346821          0.4252874   0.9033033 0.4737516

# reducida con cv
  Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2030612 0.7969388  0.510352          0.4857143   0.8782497 0.4977284
2   Test2  0.2100000 0.7900000  0.492891          0.4781609   0.8714715 0.4854142

###########################################################
original solo

Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2653061 0.7346939 0.4157303          0.6926108   0.7456885 0.5195861
2   Test2  0.2957143 0.7042857 0.3769841          0.6551724   0.7171171 0.4785894

xgboost con 2 balance semilla 123

Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2424490 0.7575510 0.4483582          0.7399015   0.7621622 0.5583643
2   Test2  0.3038095 0.6961905 0.3669725          0.6436782   0.7099099 0.4674457


xgboost con 2 balance semilla 666
 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2655102 0.7344898 0.4124847          0.6640394   0.7528958 0.5088713
2   Test2  0.2695238 0.7304762 0.4054834          0.6459770   0.7525526 0.4982270

con semilla 6897

 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2324490 0.7675510 0.4626506          0.7566502   0.7703990 0.5742056
2   Test2  0.2838095 0.7161905 0.3851641          0.6206897   0.7411411 0.4753521

SOLO hasbalance semilla 123

Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2834694 0.7165306 0.3941110          0.6857143   0.7245817 0.5005394
2   Test2  0.3066667 0.6933333 0.3672173          0.6643678   0.7009009 0.4729951

SEMILLA 6897
 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2718367 0.7281633 0.4070381          0.6837438   0.7397683 0.5102941
2   Test2  0.2852381 0.7147619 0.3894879          0.6643678   0.7279279 0.4910790
semilla 666
 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2816327 0.7183673 0.3929619          0.6600985   0.7335907 0.4926471
2   Test2  0.2771429 0.7228571 0.4000000          0.6758621   0.7351351 0.5025641


reducida plus i has balance
 Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2593878 0.7406122 0.4244392          0.7083744   0.7490347 0.5308232
2   Test2  0.2876190 0.7123810 0.3844049          0.6459770   0.7297297 0.4819897

#### svm
# p?0.26 mejor F1		
Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2167347 0.7832653 0.4814815          0.6019704   0.8306306 0.5350263
2   Test2  0.2452381 0.7547619 0.4342105          0.6068966   0.7933934 0.5062320
# p original
Dataset Error_rate  Accuracy Precision Recall_Sensitivity Specificity  F1_Score
1  Train2  0.2593878 0.7406122 0.4250585          0.7152709   0.7472329 0.5332354
2   Test2  0.2990476 0.7009524 0.3780025          0.6873563   0.7045045 0.4877651