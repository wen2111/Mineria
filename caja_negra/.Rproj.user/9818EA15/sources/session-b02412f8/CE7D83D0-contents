---
title: "Preprocessing Univ"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
date: "2025-10-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Detección de outliers univariante: variables numéricas
```{r, include=FALSE}
library(lawstat)
library(ggplot2)
library(moments)
library(EnvStats)
library(here)
library(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
knitr::opts_chunk$set(echo = TRUE)
load(here("DATA", "data.RData"))
```
Variables a estudiar:
```{r}
varNum<-c("Age", "CreditScore", "Tenure","EstimatedSalary", "Balance", "NumOfProducts",
          "TransactionFrequency","AvgTransactionAmount","DigitalEngagementScore",
          "ComplaintsCount","NetPromoterScore")
```
## Simetría de las variables
Primero ejecutamos un test de simetría para saber qué método usar para la detección de outliers en cada variable.
```{r}
p<-sapply(varNum, function(v) symmetry.test(data[[v]])$p.value)
symmetry_test <- data.frame(
  p.value = p,
  significative=(p<0.05)
)
symmetry_test <- symmetry_test[order(symmetry_test$p.value), ]
print(symmetry_test)
```

Parece que únicamente CreditScore, TransactionFrequency, Tenure y EstimatedSalary han soportado el test y pueden ser consideradas simétricas. No obstante, el p-valor de CreditScore y quizás el de TransactionFrequency merecen una inspección más a fondo.

Todas las variables con p-valor inferior a 0.05 rechazan claramente simetría.

Ahora, para reafirmar o terminar de definir las conclusiones de este test, realizaremos una inspección visual de las distribuciones para evaluar su simetría:

```{r}
n_vars <- length(varNum)
ncol <- 2
nrow <- ceiling(n_vars / ncol)

par(mfrow = c(nrow, ncol), mar = c(2, 2, 1, 1))

for (var in varNum) {
  hist(data[[var]], 
       main = paste(var),
       xlab = var,
       col = "lightblue",
       breaks = 20)
}
```
NumOfProducts y ComplaintsCount son conteos (variables discretas), por lo que no tiene mucho sentido aplicar métodos basados en cálculos numéricos

Pese a que TransactionFrequency, Tenure y EstimatedSalary pueden ser validadas como simétricas, CreditScore es algo confusa. Realizaremos un último test:
```{r}
skewness(data$CreditScore, na.rm = TRUE)
```
El valor, muy cercano a 0, de la prueba de Fisher nos permite confirmar CreditScore como variable simétrica.

No obstante, se observa una situación extraña. La distribución de Balance parece mostrar la existencia de dos poblaciones. Aproximadamente un 25% de la población tiene su cuenta en 0, y el resto parece distribuirse de manera ciertamente simétrica. 

```{r}
sum(data$Balance == 0, na.rm = TRUE)
```

Dado que son valores posibles (clientes con la cuenta en 0) y a nivel del contexto del estudio es algo que podemos entender como normal, no clasificaremos dichos valores como outliers pese a estar alejados de la población que no tiene Balance=0 en la cuenta.

Ahora procedemos a dividir nuestras variables numéricas en simétricas y no simétricas para continuar con el análisis adecuado en cada caso:

```{r}
symmetric<-c("TransactionFrequency", "Tenure", "EstimatedSalary", "CreditScore")
non_symmetric<-c("Age","AvgTransactionAmount","DigitalEngagementScore", "NetPromoterScore")
varNum
```

## Outliers variables simétricas

Procedemos a la detección de outliers para las variables simétricas. Para ello utilizaremos el rango intercuartílico (IQR), de modo que los valores que queden fuera de dicho intervalo serán reconocidos como outliers univariantes
```{r}
outlier_positions <- list()
IQROutlier <- function(variable, rmnas = TRUE) {
  IQ <- IQR(variable, na.rm = rmnas)
  intInf <- quantile(variable, probs = c(0.25, 0.75),na.rm = rmnas)[[1]] - 1.5*IQ
  intSup <- quantile(variable, probs = c(0.25, 0.75),na.rm = rmnas)[[2]] + 1.5*IQ
  posicions <- which(variable >= intSup | variable <= intInf)
  if (length(posicions) > 0) {
    cat("Existen outliers en las posiciones:", paste0(posicions, collapse = ", "))
  } else {
    cat("No existen outliers")
  }
  return(posicions)
}
for (var in symmetric) {
  cat("\nVariable:", var, "\n")
  pos <- IQROutlier(data[[var]])
  if (length(pos) > 0) {
    outlier_positions[[var]] <- pos
  }
}

outlier_positions
longitudes_s <- sapply(outlier_positions, length)
longitudes_s
```
Las variables EstimatedSalary y Tenure no tienen outliers. 

TransactionFrequency y CreditScore tienen una proporcion muy baja de outliers, pero puede tener sentido dado que son distribuciones muy compactas:
```{r}
par(mfrow = c(1, 2))
boxplot(data$TransactionFrequency, main = "TransactionFrequency")
boxplot(data$CreditScore, main = "CreditScore")
```

## Outliers variables no simétricas

Ahora, para las variables no simétricas, utilizaremos el método del Hampel Identifier. Este método usa la mediana y MAD (Median Absolute Deviation) por ser estadísticos robustos que no se ven afectados por la asimetría de los datos. A diferencia de la media y desviación estándar, no asumen distribución normal y son resistentes a valores extremos. Esto permite detectar outliers reales sin que la forma sesgada de la distribución afecte los límites de detección.

Para el parámetro que determina cuan estricto es nuestro filtro hemos escogido el umbral 3.5 tras comprobar que con 3 detectábamos demasiados outliers (6-8%), perdiendo datos válidos, mientras que con 4 nos quedábamos cortos, arriesgándonos no identificar outliers reales. El valor 3.5 nos proporciona una proporción sensata, manteniendo alrededor del 4% de outliers.
```{r}
hampelOutlier <- function(variable, mad_constant = 1, threshold = 3.5) {
  med <- median(variable, na.rm = TRUE)
  mad_val <- mad(variable, constant = mad_constant, na.rm = TRUE)
  
  lower_bound <- med - threshold * mad_val
  upper_bound <- med + threshold * mad_val
  
  which((variable < lower_bound) | (variable > upper_bound))
}

outlier_positions_non_symmetric <- list()

for (var in non_symmetric) {
  outliers <- hampelOutlier(data[[var]])
  if (length(outliers) > 0) {
    outlier_positions_non_symmetric[[var]] <- outliers
  }
}

outlier_positions_non_symmetric
longitudes_ns <- sapply(outlier_positions_non_symmetric, length)
longitudes_ns
```
Vemos que, con los valores de los parámetros escogidos, obtenemos una proporción de cerca de un 4% de outliers, exepto para DigitalEngagementScore, que parece una distribución más densa.

## Verificación por proporciones respecto a la variable salida

Ahora haremos una comparación de las proporciones segun el grupo (train o test) para evaluar si hay alguna anomalía.
```{r}
prop_test <- 30
prop_train <- 70
todas_outliers<-c(outlier_positions, outlier_positions_non_symmetric)
proporcion_outliers_completa <- data.frame(
  Variable = character(),
  Grupo = character(),
  N_Outliers = integer(),
  Total_Outliers = integer(),
  Proporcion_Outliers = numeric(),
  Proporcion_Esperada = numeric(),
  Diferencia = numeric(),
  stringsAsFactors = FALSE
)

for (var in names(todas_outliers)) {
  outliers <- todas_outliers[[var]]
  total_outliers_var <- length(outliers)
  
  if (total_outliers_var > 0) {
    outliers_test <- sum(data$group[outliers] == "test")
    outliers_train <- sum(data$group[outliers] == "train")
    
    proporcion_outliers_completa <- rbind(proporcion_outliers_completa,
      data.frame(
        Variable = var,
        Grupo = "test",
        N_Outliers = outliers_test,
        Total_Outliers = total_outliers_var,
        Proporcion_Outliers = round(outliers_test / total_outliers_var * 100, 1),
        Proporcion_Esperada = round(prop_test, 1),
        Diferencia = round((outliers_test / total_outliers_var * 100) - prop_test, 1)
      ),
      data.frame(
        Variable = var,
        Grupo = "train", 
        N_Outliers = outliers_train,
        Total_Outliers = total_outliers_var,
        Proporcion_Outliers = round(outliers_train / total_outliers_var * 100, 1),
        Proporcion_Esperada = round(prop_train, 1),
        Diferencia = round((outliers_train / total_outliers_var * 100) - prop_train, 1)
      )
    )
  }
}

# Mostrar resultados
proporcion_outliers_completa
```
Vemos que las proporciones tienen bastante sentido si las miramos segun el grupo train/test.

## Detección de valores imposibles

Ahora haremos un summary de las variables donde hemos detectado outliers para determinar si hay valores imposibles (como una persona con edad 180).

```{r}
variables_con_outliers <- names(todas_outliers)
summary(data[variables_con_outliers])
```
A partir de estos datos y del entendimiento de la naturaleza de las variables expuestas:

Rechazamos que haya valores imposibles: aceptamos los outliers como producto de la aleatoriedad natural.
